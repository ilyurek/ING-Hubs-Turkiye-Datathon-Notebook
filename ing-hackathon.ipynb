{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13324975,"sourceType":"datasetVersion","datasetId":8447607}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-21T18:59:39.057266Z","iopub.execute_input":"2025-10-21T18:59:39.057923Z","iopub.status.idle":"2025-10-21T18:59:39.065459Z","shell.execute_reply.started":"2025-10-21T18:59:39.057879Z","shell.execute_reply":"2025-10-21T18:59:39.064343Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ing-hackathon-data/sample_submission.csv\n/kaggle/input/ing-hackathon-data/referance_data.csv\n/kaggle/input/ing-hackathon-data/referance_data_test.csv\n/kaggle/input/ing-hackathon-data/customers.csv\n/kaggle/input/ing-hackathon-data/customer_history.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## FUNCTIONS","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    \"\"\"\n    Tahmin edilen olasÄ±lÄ±klarÄ±n en Ã¼st k%'sÄ±nÄ± pozitif etiketleyerek recall deÄŸerini hesaplar.\n\n    Parametreler:\n        y_true (list): GerÃ§ek ikili etiketler.\n        y_prob (list): Tahmin edilen olasÄ±lÄ±klar.\n        k (float): Pozitif etiketlenecek olasÄ±lÄ±klarÄ±n yÃ¼zdelik dilimi (varsayÄ±lan 0.1).\n\n    DÃ¶ndÃ¼rÃ¼r:\n        float: En iyi k% tahminlerindeki recall oranÄ±.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n\n    return float(tp_at_k / P) if P > 0 else 0.0\n\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    \"\"\"\n    Tahmin edilen olasÄ±lÄ±klarÄ±n en Ã¼st k%'sÄ±nÄ± pozitif etiketleyerek lift (precision/prevalence) deÄŸerini hesaplar.\n\n    Parametreler:\n        y_true (list): GerÃ§ek ikili etiketler.\n        y_prob (list): Tahmin edilen olasÄ±lÄ±klar.\n        k (float): Pozitif etiketlenecek olasÄ±lÄ±klarÄ±n yÃ¼zdelik dilimi (varsayÄ±lan 0.1).\n\n    DÃ¶ndÃ¼rÃ¼r:\n        float: En iyi k% tahminlerindeki lift deÄŸeri.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\n\ndef convert_auc_to_gini(auc):\n    \"\"\"\n    ROC AUC skorunu Gini katsayÄ±sÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n\n    Gini katsayÄ±sÄ±, ROC AUC skorunun doÄŸrusal bir dÃ¶nÃ¼ÅŸÃ¼mÃ¼dÃ¼r.\n\n    Parametreler:\n        auc (float): ROC AUC skoru (0 ile 1 arasÄ±nda).\n\n    DÃ¶ndÃ¼rÃ¼r:\n        float: Gini katsayÄ±sÄ± (-1 ile 1 arasÄ±nda).\n    \"\"\"\n    return 2 * auc - 1\n\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    \"\"\"\n    Gini, recall@10% ve lift@10% metriklerini birleÅŸtiren Ã¶zel bir metrik hesaplar.\n\n    Metrik, her bir skoru bir baseline modelin metrik deÄŸerlerine gÃ¶re oranlar ve aÅŸaÄŸÄ±daki aÄŸÄ±rlÄ±klarÄ± uygular:\n    - Gini: %40\n    - Recall@10%: %30\n    - Lift@10%: %30\n\n    Parametreler:\n        y_true (list): GerÃ§ek ikili etiketler.\n        y_prob (list): Tahmin edilen olasÄ±lÄ±klar.\n\n    DÃ¶ndÃ¼rÃ¼r:\n        float: AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ bileÅŸik skor.\n    \"\"\"\n    # final metrik iÃ§in aÄŸÄ±rlÄ±klar\n    score_weights = {\n        \"gini\": 0.4,\n        \"recall_at_10perc\": 0.3,\n        \"lift_at_10perc\": 0.3,\n    }\n\n    # baseline modelin her bir metrik iÃ§in deÄŸerleri\n    baseline_scores = {\n        \"roc_auc\": 0.6925726757936908,\n        \"recall_at_10perc\": 0.18469015795868773,\n        \"lift_at_10perc\": 1.847159286784029,\n    }\n\n    # y_prob tahminleri iÃ§in metriklerin hesaplanmasÄ±\n    roc_auc = roc_auc_score(y_true, y_prob)\n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\n        \"roc_auc\": roc_auc,\n        \"recall_at_10perc\": recall_at_10perc,\n        \"lift_at_10perc\": lift_at_10perc,\n    }\n\n    # roc auc deÄŸerlerinin gini deÄŸerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi\n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n\n    # baseline modeline oranlama\n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"]\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"]\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"]\n\n    # aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ metriÄŸin hesaplanmasÄ±\n    final_score = (\n        final_gini_score * score_weights[\"gini\"] +\n        final_recall_score * score_weights[\"recall_at_10perc\"] + \n        final_lift_score * score_weights[\"lift_at_10perc\"]\n    )\n    return final_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:24:05.024960Z","iopub.execute_input":"2025-10-17T20:24:05.025434Z","iopub.status.idle":"2025-10-17T20:24:05.408358Z","shell.execute_reply.started":"2025-10-17T20:24:05.025409Z","shell.execute_reply":"2025-10-17T20:24:05.407274Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Understanding of the Data with EDA","metadata":{}},{"cell_type":"code","source":"customer_history = pd.read_csv(\"/kaggle/input/ing-hackathon-data/customer_history.csv\")\ncustomers = pd.read_csv(\"/kaggle/input/ing-hackathon-data/customers.csv\")\nreference_data= pd.read_csv(\"/kaggle/input/ing-hackathon-data/referance_data.csv\")\nreference_data_test = pd.read_csv(\"/kaggle/input/ing-hackathon-data/referance_data_test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/ing-hackathon-data/sample_submission.csv\")\n\nprint(\"ðŸ“Š VERÄ° SETÄ° BOYUTLARI:\")\nprint(f\"customer_history: {customer_history.shape}\")\nprint(f\"customers: {customers.shape}\")\nprint(f\"reference_data: {reference_data.shape}\")\nprint(f\"reference_data_test: {reference_data_test.shape}\")\nprint(f\"sample_submission: {sample_submission.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T20:15:37.641522Z","iopub.status.idle":"2025-10-11T20:15:37.641784Z","shell.execute_reply.started":"2025-10-11T20:15:37.641643Z","shell.execute_reply":"2025-10-11T20:15:37.641654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Assumptions-Ideas : Tenure - Retention should be correlated. Possible idea that retired people naturally will pass away so the churn posibility should be much higher then the other work groups, possible students should have a behouvior to be churn.\n\nCustomers may tend to reduce their usage of products before churning.\n\nThe risk of churn of the customer are the fact that the salary card belongs in another bank in. (Define a feature that mirror this effect) \n","metadata":{}},{"cell_type":"code","source":"# impute work type feature with semantic imputation\ncustomers.loc[customers['work_type'] == 'Student', 'work_sector'] = 'Dependent'\ncustomers.loc[customers['work_type'] == 'Unemployed', 'work_sector'] = 'Unemployed'\ncustomers.loc[customers['work_type'] == 'Retired', 'work_sector'] = 'Pension'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:31:43.645664Z","iopub.execute_input":"2025-10-11T13:31:43.645996Z","iopub.status.idle":"2025-10-11T13:31:43.708924Z","shell.execute_reply.started":"2025-10-11T13:31:43.645954Z","shell.execute_reply":"2025-10-11T13:31:43.707509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# work_sector distribution\nplt.figure(figsize=(10,6))\nsns.countplot(data=customers, x='work_sector', order=customers['work_sector'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title('Distribution of Work Sector')\nplt.ylabel('Count')\nplt.xlabel('Work Sector')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:39:13.568175Z","iopub.execute_input":"2025-10-11T16:39:13.569524Z","iopub.status.idle":"2025-10-11T16:39:15.184243Z","shell.execute_reply.started":"2025-10-11T16:39:13.569433Z","shell.execute_reply":"2025-10-11T16:39:15.183034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# work_type distribution\nplt.figure(figsize=(8,6))\nsns.countplot(data=customers, x='work_type', order=customers['work_type'].value_counts().index, palette='Set2')\nplt.title('Distribution of Work Type')\nplt.xlabel('Work Type')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:39:17.383441Z","iopub.execute_input":"2025-10-11T16:39:17.383777Z","iopub.status.idle":"2025-10-11T16:39:17.650068Z","shell.execute_reply.started":"2025-10-11T16:39:17.383748Z","shell.execute_reply":"2025-10-11T16:39:17.648992Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As an inference, we can say that actively earning money leads to using a bank's products, which is expected. ING bank should also capture the self-employed attention. The number of self-employed customer is lower then the other working groups.","metadata":{}},{"cell_type":"code","source":"# tenure distribution by work type\nplt.figure(figsize=(10,6))\nsns.boxplot(data=customers, x='work_type', y='tenure', palette='Set3')\nplt.title('Tenure Distribution by Work Type')\nplt.xlabel('Work Type')\nplt.ylabel('Tenure (months)')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T10:57:34.196306Z","iopub.execute_input":"2025-10-11T10:57:34.196573Z","iopub.status.idle":"2025-10-11T10:57:34.487151Z","shell.execute_reply.started":"2025-10-11T10:57:34.196556Z","shell.execute_reply":"2025-10-11T10:57:34.485965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Overall, we can infer from this graph that customer tenure (the length of time someone has been a customer) tends to increase with age and financial stability. The tenure for individuals in the unemployed category is lower than for the working groups but is still significant. This could imply that customers do not immediately end their banking relationship upon losing a job, or that they had already been customers for a considerable time before becoming unemployed.","metadata":{}},{"cell_type":"code","source":"# tenure distribution by work_sector\nplt.figure(figsize=(12,6))\nsns.boxplot(data=customers, x='work_sector', y='tenure', palette='Set3')\nplt.title('Tenure Distribution by Work Sector')\nplt.xlabel('Work Sector')\nplt.ylabel('Tenure (months)')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T10:59:52.321036Z","iopub.execute_input":"2025-10-11T10:59:52.321316Z","iopub.status.idle":"2025-10-11T10:59:52.662311Z","shell.execute_reply.started":"2025-10-11T10:59:52.321297Z","shell.execute_reply":"2025-10-11T10:59:52.661352Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This suggests that once a customer is established in their professional life, the specific type of sector they work in has little impact on their loyalty or tenure with the bank. A tech employee and an educator have similarly long-standing relationships with their bank. These groups form the stable, core customer base.","metadata":{}},{"cell_type":"code","source":"# tenure dist by religion\nplt.figure(figsize=(12,6))\nsns.boxplot(data=customers, x='religion', y='tenure', palette='Set2')\nplt.title('Tenure Distribution by Religion')\nplt.xlabel('Religion')\nplt.ylabel('Tenure (months)')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T11:02:13.448183Z","iopub.execute_input":"2025-10-11T11:02:13.448499Z","iopub.status.idle":"2025-10-11T11:02:13.712499Z","shell.execute_reply.started":"2025-10-11T11:02:13.448477Z","shell.execute_reply":"2025-10-11T11:02:13.711657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There is no correlation between religion and tenure here.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.boxplot(data=customers, x='province', y='tenure', palette='Set3')\nplt.title('Tenure Distribution by Province')\nplt.xlabel('Province')\nplt.ylabel('Tenure (months)')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T11:19:39.093109Z","iopub.execute_input":"2025-10-11T11:19:39.093792Z","iopub.status.idle":"2025-10-11T11:19:39.442282Z","shell.execute_reply.started":"2025-10-11T11:19:39.093764Z","shell.execute_reply":"2025-10-11T11:19:39.441365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There is no correlation between the tenure and the province.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(data=customers, x='age', y='tenure', alpha=0.6)\nplt.title('Tenure vs Age')\nplt.xlabel('Age')\nplt.ylabel('Tenure (months)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T11:20:37.837044Z","iopub.execute_input":"2025-10-11T11:20:37.837815Z","iopub.status.idle":"2025-10-11T11:20:38.514926Z","shell.execute_reply.started":"2025-10-11T11:20:37.837785Z","shell.execute_reply":"2025-10-11T11:20:38.514051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The most obvious takeaway is the strong positive correlation between age and tenure. As a customer's age increases, their potential tenure with the bank also increases. This visually confirms why the \"Pensioner/Retired\" group in the previous box plots had the highest tenure. The sharp, linear edge on the upper-left side of the data cloud is very significant. This line represents the maximum possible tenure for any given age. The dots along this boundary are the \"lifelong loyal\" customersâ€”those who joined the bank at a young age (likely 18-20) and have never left. For instance, a 40-year-old customer can have a maximum tenure of 240 months (20 years), which aligns perfectly with this line.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.boxplot(data=customers, x='work_sector', y='tenure', hue='gender', palette='Set3')\nplt.title('Tenure by Work Sector and Gender')\nplt.xlabel('Work Sector')\nplt.ylabel('Tenure (months)')\nplt.xticks(rotation=45)\nplt.legend(title='Gender')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T11:28:21.358211Z","iopub.execute_input":"2025-10-11T11:28:21.358525Z","iopub.status.idle":"2025-10-11T11:28:22.114722Z","shell.execute_reply.started":"2025-10-11T11:28:21.358501Z","shell.execute_reply":"2025-10-11T11:28:22.113688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Some of the gender related graphics has been deleted and no proof that find there is a relation between the gender and tenure.","metadata":{}},{"cell_type":"markdown","source":"## DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"# merge customer_history and reference_date tables\ncustomer_history_reference_data = customer_history.merge(reference_data, on='cust_id', how='inner')\ncustomer_history_reference_data.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:23.109093Z","iopub.execute_input":"2025-10-11T13:32:23.109530Z","iopub.status.idle":"2025-10-11T13:32:23.675581Z","shell.execute_reply.started":"2025-10-11T13:32:23.109503Z","shell.execute_reply":"2025-10-11T13:32:23.674286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data.isnull().sum()\n\n#customer_history_reference_data[customer_history_reference_data[\"cust_id\"]==0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:25.727758Z","iopub.execute_input":"2025-10-11T13:32:25.728079Z","iopub.status.idle":"2025-10-11T13:32:26.163152Z","shell.execute_reply.started":"2025-10-11T13:32:25.728052Z","shell.execute_reply":"2025-10-11T13:32:26.162226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify customers who have credit cards and those who use EFT, meaning they have deposit accounts\ncustomer_history_reference_data['has_cc'] = np.where(customer_history_reference_data['cc_transaction_all_cnt'].notna(), 1, 0)\ncustomer_history_reference_data['has_eft'] = np.where(customer_history_reference_data['mobile_eft_all_cnt'].notna(), 1, 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:27.880871Z","iopub.execute_input":"2025-10-11T13:32:27.881166Z","iopub.status.idle":"2025-10-11T13:32:27.930294Z","shell.execute_reply.started":"2025-10-11T13:32:27.881145Z","shell.execute_reply":"2025-10-11T13:32:27.929304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unique values for has_eft and has_cc\ncustomer_history_reference_data.groupby(['has_eft','has_cc'])['cust_id'].nunique()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:29.630255Z","iopub.execute_input":"2025-10-11T13:32:29.630655Z","iopub.status.idle":"2025-10-11T13:32:29.931688Z","shell.execute_reply.started":"2025-10-11T13:32:29.630631Z","shell.execute_reply":"2025-10-11T13:32:29.930633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# There is no significant evidence having a credit card or not, or having a eft.\nchurn_summary = (\n    customer_history_reference_data\n    .groupby(['has_eft', 'has_cc'])['churn']\n    .mean()\n    .reset_index()\n)\nchurn_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:31.008916Z","iopub.execute_input":"2025-10-11T13:32:31.009256Z","iopub.status.idle":"2025-10-11T13:32:31.235739Z","shell.execute_reply.started":"2025-10-11T13:32:31.009228Z","shell.execute_reply":"2025-10-11T13:32:31.234403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Merge customers and customer_history_reference_data, all information will be in the same data","metadata":{}},{"cell_type":"code","source":"cust_hist_ref_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:38:06.756729Z","iopub.execute_input":"2025-10-11T13:38:06.757053Z","iopub.status.idle":"2025-10-11T13:38:06.776258Z","shell.execute_reply.started":"2025-10-11T13:38:06.757030Z","shell.execute_reply":"2025-10-11T13:38:06.774993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_ref_df = customer_history_reference_data.merge(customers, on='cust_id', how='inner')\ncust_hist_ref_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:32:34.421104Z","iopub.execute_input":"2025-10-11T13:32:34.421553Z","iopub.status.idle":"2025-10-11T13:32:35.630291Z","shell.execute_reply.started":"2025-10-11T13:32:34.421530Z","shell.execute_reply":"2025-10-11T13:32:35.629208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Impute null values as 0 (we keep the information about the nulls already)\ncust_hist_ref_df = cust_hist_ref_df.fillna(0)\ncust_hist_ref_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:13:15.341935Z","iopub.execute_input":"2025-10-11T16:13:15.342991Z","iopub.status.idle":"2025-10-11T16:13:18.538579Z","shell.execute_reply.started":"2025-10-11T16:13:15.342955Z","shell.execute_reply":"2025-10-11T16:13:18.537662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change dates as datetime\ncust_hist_ref_df['date'] = pd.to_datetime(cust_hist_ref_df['date'])\ncust_hist_ref_df['ref_date'] = pd.to_datetime(cust_hist_ref_df['ref_date'])\n\n# Smaller dates \ncust_hist_ref_df = cust_hist_ref_df[cust_hist_ref_df['date'] < cust_hist_ref_df['ref_date']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:26:19.409516Z","iopub.execute_input":"2025-10-11T16:26:19.409885Z","iopub.status.idle":"2025-10-11T16:26:20.712350Z","shell.execute_reply.started":"2025-10-11T16:26:19.409861Z","shell.execute_reply":"2025-10-11T16:26:20.711388Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"summary_df = cust_hist_ref_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt = ('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt = ('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt = ('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt = ('cc_transaction_all_cnt', 'mean'),\n    avg_active_products = ('active_product_category_nbr', 'mean'),\n    has_cc = ('has_cc', 'max'),\n    has_eft = ('has_eft', 'max'),\n    gender = ('gender', 'first'),\n    age = ('age', 'first'),\n    province = ('province', 'first'),\n    religion = ('religion', 'first'),\n    work_type = ('work_type', 'first'),\n    work_sector = ('work_sector', 'first'),\n    tenure = ('tenure', 'first'),\n    churn = ('churn', 'first')  # hedef deÄŸiÅŸken\n).reset_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:31:42.495029Z","iopub.execute_input":"2025-10-11T16:31:42.495388Z","iopub.status.idle":"2025-10-11T16:31:44.334850Z","shell.execute_reply.started":"2025-10-11T16:31:42.495364Z","shell.execute_reply":"2025-10-11T16:31:44.333738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary_df.head(15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:32:30.742075Z","iopub.execute_input":"2025-10-11T16:32:30.742518Z","iopub.status.idle":"2025-10-11T16:32:30.762606Z","shell.execute_reply.started":"2025-10-11T16:32:30.742491Z","shell.execute_reply":"2025-10-11T16:32:30.761542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Age distribution by Churn\nplt.figure(figsize=(10,6))\nsns.histplot(data=summary_df, x=\"age\", hue=\"churn\", multiple=\"stack\", bins=20)\nplt.title(\"Age daÄŸÄ±lÄ±mÄ± - Churn Durumu\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"MÃ¼ÅŸteri SayÄ±sÄ±\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:40:07.816859Z","iopub.execute_input":"2025-10-11T16:40:07.817251Z","iopub.status.idle":"2025-10-11T16:40:08.224566Z","shell.execute_reply.started":"2025-10-11T16:40:07.817222Z","shell.execute_reply":"2025-10-11T16:40:08.223603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This indicates that middle-aged customers have the highest propensity to churn. Customers in this age range are often making major financial decisions (e.g., mortgages, investments, children's education). Consequently, they may be more open to switching banks for better offers or services. It is critically important for the bank to focus its retention efforts primarily on this segment. This confirms once again that older customers are the most loyal segment. The churn rate in this group is very low. This finding is perfectly consistent with the high tenure data we saw in the previous graphs. Younger customers generally exhibit a loyal profile. This group represents both current stability and future potential for the bank.","metadata":{}},{"cell_type":"code","source":"summary_df['age_group'] = summary_df['age'].apply(categorize_age)\nsummary_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:46:28.847412Z","iopub.execute_input":"2025-10-11T16:46:28.847768Z","iopub.status.idle":"2025-10-11T16:46:28.907222Z","shell.execute_reply.started":"2025-10-11T16:46:28.847745Z","shell.execute_reply":"2025-10-11T16:46:28.905679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Provice by Churn\nplt.figure(figsize=(12,6))\nsns.countplot(data=summary_df, x=\"province\", hue=\"churn\")\nplt.title(\"Province bazÄ±nda Churn SayÄ±larÄ±\")\nplt.xlabel(\"Province\")\nplt.ylabel(\"MÃ¼ÅŸteri SayÄ±sÄ±\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:49:05.400607Z","iopub.execute_input":"2025-10-11T16:49:05.401024Z","iopub.status.idle":"2025-10-11T16:49:05.846690Z","shell.execute_reply.started":"2025-10-11T16:49:05.400998Z","shell.execute_reply":"2025-10-11T16:49:05.845228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,6))\nsns.countplot(data=summary_df, x=\"religion\", hue=\"churn\")\nplt.title(\"Religion bazÄ±nda Churn SayÄ±larÄ±\")\nplt.xlabel(\"Religion\")\nplt.ylabel(\"MÃ¼ÅŸteri SayÄ±sÄ±\")\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:53:15.459899Z","iopub.execute_input":"2025-10-11T16:53:15.460349Z","iopub.status.idle":"2025-10-11T16:53:15.764302Z","shell.execute_reply.started":"2025-10-11T16:53:15.460320Z","shell.execute_reply":"2025-10-11T16:53:15.762809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The fact that 'U' is the largest category often represents cases where this information was \"Unspecified\" or \"Unknown,\" which is common in such datasets. The other letters ('C', 'I', 'M', 'O') likely represent specific faith groups (\"Christian,\" \"Jewish/Islamic,\" \"Muslim,\" \"Other\"). a customer's religious affiliation does not influence their decision to leave the bank. It would be far more effective for the bank to focus its resources and attention on segmentations that have a real impact on churn, such as age and province, as we identified in the previous analyses","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.boxplot(data=summary_df, x=\"churn\", y=\"tenure\")\nplt.title(\"Churn durumuna gÃ¶re Tenure daÄŸÄ±lÄ±mÄ±\")\nplt.xlabel(\"Churn\")\nplt.ylabel(\"Tenure\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:57:55.147121Z","iopub.execute_input":"2025-10-11T16:57:55.147664Z","iopub.status.idle":"2025-10-11T16:57:55.363185Z","shell.execute_reply.started":"2025-10-11T16:57:55.147637Z","shell.execute_reply":"2025-10-11T16:57:55.362078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EVALUATION DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"reference_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:28.663914Z","iopub.execute_input":"2025-10-11T17:44:28.664357Z","iopub.status.idle":"2025-10-11T17:44:28.676768Z","shell.execute_reply.started":"2025-10-11T17:44:28.664329Z","shell.execute_reply":"2025-10-11T17:44:28.675735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_eva = customer_history.merge(reference_data, on='cust_id', how='inner')\ncustomer_history_reference_data_eva.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:30.647388Z","iopub.execute_input":"2025-10-11T17:44:30.647735Z","iopub.status.idle":"2025-10-11T17:44:31.325547Z","shell.execute_reply.started":"2025-10-11T17:44:30.647711Z","shell.execute_reply":"2025-10-11T17:44:31.324507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify customers who have credit cards and those who use EFT, meaning they have deposit accounts\ncustomer_history_reference_data_eva['has_cc'] = np.where(customer_history_reference_data_eva['cc_transaction_all_cnt'].notna(), 1, 0)\ncustomer_history_reference_data_eva['has_eft'] = np.where(customer_history_reference_data_eva['mobile_eft_all_cnt'].notna(), 1, 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:33.044353Z","iopub.execute_input":"2025-10-11T17:44:33.044688Z","iopub.status.idle":"2025-10-11T17:44:33.093182Z","shell.execute_reply.started":"2025-10-11T17:44:33.044666Z","shell.execute_reply":"2025-10-11T17:44:33.092321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_ref_df_eva = customer_history_reference_data_eva.merge(customers, on='cust_id', how='inner')\ncust_hist_ref_df_eva.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:34.736693Z","iopub.execute_input":"2025-10-11T17:44:34.737009Z","iopub.status.idle":"2025-10-11T17:44:36.479162Z","shell.execute_reply.started":"2025-10-11T17:44:34.736986Z","shell.execute_reply":"2025-10-11T17:44:36.478147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_ref_df_eva = cust_hist_ref_df_eva.fillna(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:37.743723Z","iopub.execute_input":"2025-10-11T17:44:37.744181Z","iopub.status.idle":"2025-10-11T17:44:40.038904Z","shell.execute_reply.started":"2025-10-11T17:44:37.744092Z","shell.execute_reply":"2025-10-11T17:44:40.037724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_ref_df_eva['date'] = pd.to_datetime(cust_hist_ref_df_eva['date'])\ncust_hist_ref_df_eva['ref_date'] = pd.to_datetime(cust_hist_ref_df_eva['ref_date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:40.830594Z","iopub.execute_input":"2025-10-11T17:44:40.830926Z","iopub.status.idle":"2025-10-11T17:44:41.700328Z","shell.execute_reply.started":"2025-10-11T17:44:40.830902Z","shell.execute_reply":"2025-10-11T17:44:41.699351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_ref_df_eva.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:42.267353Z","iopub.execute_input":"2025-10-11T17:44:42.267652Z","iopub.status.idle":"2025-10-11T17:44:42.285541Z","shell.execute_reply.started":"2025-10-11T17:44:42.267633Z","shell.execute_reply":"2025-10-11T17:44:42.284405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df = cust_hist_ref_df_eva[cust_hist_ref_df_eva['ref_date'] == cust_hist_ref_df_eva['date']]\nfiltered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:44.613828Z","iopub.execute_input":"2025-10-11T17:44:44.614112Z","iopub.status.idle":"2025-10-11T17:44:44.700597Z","shell.execute_reply.started":"2025-10-11T17:44:44.614094Z","shell.execute_reply":"2025-10-11T17:44:44.699638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df['age_group'] = filtered_df['age'].apply(categorize_age)\nfiltered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:44:47.709759Z","iopub.execute_input":"2025-10-11T17:44:47.710046Z","iopub.status.idle":"2025-10-11T17:44:47.758686Z","shell.execute_reply.started":"2025-10-11T17:44:47.710027Z","shell.execute_reply":"2025-10-11T17:44:47.757756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"column_mapping = {\n    'mobile_eft_all_cnt': 'avg_eft_cnt',\n    'mobile_eft_all_amt': 'avg_eft_amt',\n    'cc_transaction_all_amt': 'avg_cc_amt',\n    'cc_transaction_all_cnt': 'avg_cc_cnt',\n    'active_product_category_nbr': 'avg_active_products'\n}\n\n# SÃ¼tun isimlerini deÄŸiÅŸtir\nfiltered_df = filtered_df.rename(columns=column_mapping)\nfiltered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:48:20.024571Z","iopub.execute_input":"2025-10-11T17:48:20.024931Z","iopub.status.idle":"2025-10-11T17:48:20.083649Z","shell.execute_reply.started":"2025-10-11T17:48:20.024906Z","shell.execute_reply":"2025-10-11T17:48:20.082619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df = filtered_df.drop(columns=['date'])\nfiltered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:49:47.518905Z","iopub.execute_input":"2025-10-11T17:49:47.519247Z","iopub.status.idle":"2025-10-11T17:49:47.544572Z","shell.execute_reply.started":"2025-10-11T17:49:47.519223Z","shell.execute_reply":"2025-10-11T17:49:47.543570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df = filtered_df[summary_df.columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:50:53.923113Z","iopub.execute_input":"2025-10-11T17:50:53.923556Z","iopub.status.idle":"2025-10-11T17:50:53.951598Z","shell.execute_reply.started":"2025-10-11T17:50:53.923530Z","shell.execute_reply":"2025-10-11T17:50:53.950624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:50:55.912389Z","iopub.execute_input":"2025-10-11T17:50:55.912734Z","iopub.status.idle":"2025-10-11T17:50:55.931057Z","shell.execute_reply.started":"2025-10-11T17:50:55.912710Z","shell.execute_reply":"2025-10-11T17:50:55.929988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:50:57.624584Z","iopub.execute_input":"2025-10-11T17:50:57.624901Z","iopub.status.idle":"2025-10-11T17:50:57.642260Z","shell.execute_reply.started":"2025-10-11T17:50:57.624881Z","shell.execute_reply":"2025-10-11T17:50:57.641389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:28:36.193288Z","iopub.execute_input":"2025-10-11T19:28:36.193710Z","iopub.status.idle":"2025-10-11T19:28:36.220210Z","shell.execute_reply.started":"2025-10-11T19:28:36.193682Z","shell.execute_reply":"2025-10-11T19:28:36.219341Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\n# Data\ntarget = 'churn'\ndrop_cols = ['cust_id', 'ref_date', target]\n\nX_train = summary_df.drop(columns=drop_cols)\ny_train = summary_df[target]\n\nX_eval = filtered_df.drop(columns=drop_cols)\ny_eval = filtered_df[target]\n\ncategorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n\n# Optuna objective (hÄ±zlÄ± versiyon)\ndef objective(trial):\n    params = {\n        \"iterations\": 500,  # daha kÄ±sa\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n        \"depth\": trial.suggest_int(\"depth\", 4, 9),\n        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 5, log=True),\n        \"eval_metric\": \"AUC\",\n        \"random_seed\": 42,\n        \"verbose\": 0,\n        \"early_stopping_rounds\": 30,\n    }\n\n    model = CatBoostClassifier(**params)\n    model.fit(X_train, y_train, cat_features=categorical_features, eval_set=(X_eval, y_eval), use_best_model=True)\n    \n    y_pred_prob = model.predict_proba(X_eval)[:,1]\n    auc = roc_auc_score(y_eval, y_pred_prob)\n    return auc\n\n# HÄ±zlÄ± Optuna\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)  # 10 trial ile hÄ±zlÄ±\n\nprint(\"Best Params:\", study.best_params)\nprint(\"Best CV AUC:\", study.best_value)\n\n# Final model\nbest_params = study.best_params\nbest_params.update({\"iterations\": 500, \"eval_metric\": \"AUC\", \"random_seed\": 42, \"verbose\": 100})\nfinal_model = CatBoostClassifier(**best_params)\nfinal_model.fit(X_train, y_train, cat_features=categorical_features, eval_set=(X_eval, y_eval), use_best_model=True)\n\n# Prediction 0/1\ny_prob = final_model.predict_proba(X_eval)[:,1]\ny_pred = (y_prob >= 0.5).astype(int)\n\n# DeÄŸerlendirme\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nprint(\"ROC AUC:\", roc_auc_score(y_eval, y_prob))\nprint(\"Accuracy:\", accuracy_score(y_eval, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T08:42:02.316057Z","iopub.execute_input":"2025-10-12T08:42:02.316432Z","iopub.status.idle":"2025-10-12T08:42:03.029628Z","shell.execute_reply.started":"2025-10-12T08:42:02.316399Z","shell.execute_reply":"2025-10-12T08:42:03.028019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ã–zel metrikler\nscore = ing_hubs_datathon_metric(y_eval, y_prob)\nrecall10 = recall_at_k(y_eval, y_prob, k=0.1)\nlift10 = lift_at_k(y_eval, y_prob, k=0.1)\n\nprint(\"ING Hubs Metric:\", score)\nprint(\"Recall@10%:\", recall10)\nprint(\"Lift@10%:\", lift10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:25:27.628215Z","iopub.execute_input":"2025-10-11T19:25:27.628604Z","iopub.status.idle":"2025-10-11T19:25:27.755675Z","shell.execute_reply.started":"2025-10-11T19:25:27.628578Z","shell.execute_reply":"2025-10-11T19:25:27.754492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------\n# 1. Date features\n# ----------------------\nsummary_df['ref_month'] = summary_df['ref_date'].dt.month\nsummary_df['ref_quarter'] = summary_df['ref_date'].dt.quarter\nsummary_df['ref_weekday'] = summary_df['ref_date'].dt.weekday\n\n# Tenure bucket\ndef tenure_bucket(tenure):\n    if tenure <= 12:\n        return 'new'\n    elif tenure <= 36:\n        return 'medium'\n    else:\n        return 'long'\n\nsummary_df['tenure_bucket'] = summary_df['tenure'].apply(tenure_bucket)\n\n# ----------------------\n# 2. Financial trends (delta features)\n# ----------------------\n# Past 3-6 month delta iÃ§in\npast_df = cust_hist_ref_df.copy()\npast_df['months_diff'] = ((past_df['ref_date'].dt.year - past_df['date'].dt.year) * 12 +\n                          (past_df['ref_date'].dt.month - past_df['date'].dt.month))\n\n# Son 3 ay\nlast_3m_df = past_df[past_df['months_diff'] <= 3]\ntrend_3m = last_3m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_last_3m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_last_3m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_last_3m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_last_3m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# 3-6 ay\nlast_6m_df = past_df[(past_df['months_diff'] > 3) & (past_df['months_diff'] <= 6)]\ntrend_3_6m = last_6m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_3_6m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_3_6m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_3_6m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_3_6m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# Merge trend features\nsummary_df = summary_df.merge(trend_3m, on=['cust_id','ref_date'], how='left')\nsummary_df = summary_df.merge(trend_3_6m, on=['cust_id','ref_date'], how='left')\n\n# Delta features\nsummary_df['delta_eft_cnt'] = summary_df['avg_eft_cnt_last_3m'] - summary_df['avg_eft_cnt_3_6m']\nsummary_df['delta_eft_amt'] = summary_df['avg_eft_amt_last_3m'] - summary_df['avg_eft_amt_3_6m']\nsummary_df['delta_cc_cnt'] = summary_df['avg_cc_cnt_last_3m'] - summary_df['avg_cc_cnt_3_6m']\nsummary_df['delta_cc_amt'] = summary_df['avg_cc_amt_last_3m'] - summary_df['avg_cc_amt_3_6m']\n\n# ----------------------\n# 3. Product diversity\n# ----------------------\nsummary_df['active_product_ratio'] = summary_df['has_cc'] / (summary_df['avg_active_products'] + 1e-6)\n\n# ----------------------\n# 4. Recency & frequency\n# ----------------------\n# Son EFT ve CC iÅŸleminin ay olarak uzaklÄ±ÄŸÄ±\nsummary_df['last_eft_months'] = summary_df['avg_eft_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\nsummary_df['last_cc_months'] = summary_df['avg_cc_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\n\n# Son 3 ayda toplam iÅŸlem sayÄ±sÄ±\nsummary_df['total_trx_last_3m'] = summary_df['avg_eft_cnt_last_3m'] + summary_df['avg_cc_cnt_last_3m']\nsummary_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:13:26.117999Z","iopub.execute_input":"2025-10-11T18:13:26.118526Z","iopub.status.idle":"2025-10-11T18:13:29.619919Z","shell.execute_reply.started":"2025-10-11T18:13:26.118493Z","shell.execute_reply":"2025-10-11T18:13:29.618940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier, Pool\n\n# Feature importance al\nfeature_importances = final_model.get_feature_importance(type='FeatureImportance')\nfeature_names = X_train.columns\n\n# DataFrame olarak gÃ¶rmek\nfi_df = pd.DataFrame({\n    'feature': feature_names,\n    'importance': feature_importances\n}).sort_values(by='importance', ascending=False)\n\nprint(fi_df)\n\n# GÃ¶rselleÅŸtirmek iÃ§in\nplt.figure(figsize=(10,6))\nplt.barh(fi_df['feature'], fi_df['importance'])\nplt.gca().invert_yaxis()\nplt.title(\"CatBoost Feature Importance\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:25:38.379723Z","iopub.execute_input":"2025-10-11T19:25:38.380058Z","iopub.status.idle":"2025-10-11T19:25:38.780428Z","shell.execute_reply.started":"2025-10-11T19:25:38.380032Z","shell.execute_reply":"2025-10-11T19:25:38.779360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------\n# 1. Date features\n# ----------------------\nfiltered_df['ref_month'] = filtered_df['ref_date'].dt.month\nfiltered_df['ref_quarter'] = filtered_df['ref_date'].dt.quarter\nfiltered_df['ref_weekday'] = filtered_df['ref_date'].dt.weekday\n\n# Tenure bucket\nfiltered_df['tenure_bucket'] = filtered_df['tenure'].apply(tenure_bucket)\n\n# ----------------------\n# 2. Financial trends (delta features)\n# ----------------------\n# Past 3-6 month delta iÃ§in\npast_filtered_df = cust_hist_ref_df.copy()  # filtered_df zaten tek satÄ±r olduÄŸu iÃ§in geÃ§miÅŸ veriyi kullanÄ±yoruz\npast_filtered_df['months_diff'] = ((past_filtered_df['ref_date'].dt.year - past_filtered_df['date'].dt.year) * 12 +\n                                   (past_filtered_df['ref_date'].dt.month - past_filtered_df['date'].dt.month))\n\n# Son 3 ay\nlast_3m_df = past_filtered_df[past_filtered_df['months_diff'] <= 3]\ntrend_3m_eval = last_3m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_last_3m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_last_3m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_last_3m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_last_3m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# 3-6 ay\nlast_6m_df = past_filtered_df[(past_filtered_df['months_diff'] > 3) & (past_filtered_df['months_diff'] <= 6)]\ntrend_3_6m_eval = last_6m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_3_6m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_3_6m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_3_6m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_3_6m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# Merge trend features\nfiltered_df = filtered_df.merge(trend_3m_eval, on=['cust_id','ref_date'], how='left')\nfiltered_df = filtered_df.merge(trend_3_6m_eval, on=['cust_id','ref_date'], how='left')\n\n# Delta features\nfiltered_df['delta_eft_cnt'] = filtered_df['avg_eft_cnt_last_3m'] - filtered_df['avg_eft_cnt_3_6m']\nfiltered_df['delta_eft_amt'] = filtered_df['avg_eft_amt_last_3m'] - filtered_df['avg_eft_amt_3_6m']\nfiltered_df['delta_cc_cnt'] = filtered_df['avg_cc_cnt_last_3m'] - filtered_df['avg_cc_cnt_3_6m']\nfiltered_df['delta_cc_amt'] = filtered_df['avg_cc_amt_last_3m'] - filtered_df['avg_cc_amt_3_6m']\n\n# ----------------------\n# 3. Product diversity\n# ----------------------\nfiltered_df['active_product_ratio'] = filtered_df['has_cc'] / (filtered_df['avg_active_products'] + 1e-6)\n\n# ----------------------\n# 4. Recency & frequency\n# ----------------------\nfiltered_df['last_eft_months'] = filtered_df['avg_eft_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\nfiltered_df['last_cc_months'] = filtered_df['avg_cc_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\n\nfiltered_df['total_trx_last_3m'] = filtered_df['avg_eft_cnt_last_3m'] + filtered_df['avg_cc_cnt_last_3m']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:14:17.385337Z","iopub.execute_input":"2025-10-11T18:14:17.385821Z","iopub.status.idle":"2025-10-11T18:14:19.009386Z","shell.execute_reply.started":"2025-10-11T18:14:17.385790Z","shell.execute_reply":"2025-10-11T18:14:19.008382Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PREDICTION","metadata":{}},{"cell_type":"code","source":"reference_data_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:13.799012Z","iopub.execute_input":"2025-10-11T18:56:13.799405Z","iopub.status.idle":"2025-10-11T18:56:13.809067Z","shell.execute_reply.started":"2025-10-11T18:56:13.799380Z","shell.execute_reply":"2025-10-11T18:56:13.807938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_pred = customer_history.merge(reference_data_test, on='cust_id', how='inner')\ncustomer_history_reference_data_pred.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:15.789394Z","iopub.execute_input":"2025-10-11T18:56:15.789702Z","iopub.status.idle":"2025-10-11T18:56:16.151359Z","shell.execute_reply.started":"2025-10-11T18:56:15.789682Z","shell.execute_reply":"2025-10-11T18:56:16.150035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify customers who have credit cards and those who use EFT, meaning they have deposit accounts\ncustomer_history_reference_data_pred['has_cc'] = np.where(customer_history_reference_data_pred['cc_transaction_all_cnt'].notna(), 1, 0)\ncustomer_history_reference_data_pred['has_eft'] = np.where(customer_history_reference_data_pred['mobile_eft_all_cnt'].notna(), 1, 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:17.549047Z","iopub.execute_input":"2025-10-11T18:56:17.549512Z","iopub.status.idle":"2025-10-11T18:56:17.575654Z","shell.execute_reply.started":"2025-10-11T18:56:17.549423Z","shell.execute_reply":"2025-10-11T18:56:17.574544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_pred = customer_history_reference_data_pred.merge(customers, on='cust_id', how='inner')\ncustomer_history_reference_data_pred.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:19.127545Z","iopub.execute_input":"2025-10-11T18:56:19.127847Z","iopub.status.idle":"2025-10-11T18:56:19.652324Z","shell.execute_reply.started":"2025-10-11T18:56:19.127827Z","shell.execute_reply":"2025-10-11T18:56:19.651183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_pred = customer_history_reference_data_pred.fillna(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:21.372692Z","iopub.execute_input":"2025-10-11T18:56:21.372994Z","iopub.status.idle":"2025-10-11T18:56:22.390404Z","shell.execute_reply.started":"2025-10-11T18:56:21.372976Z","shell.execute_reply":"2025-10-11T18:56:22.389395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_pred['date'] = pd.to_datetime(customer_history_reference_data_pred['date'])\ncustomer_history_reference_data_pred['ref_date'] = pd.to_datetime(customer_history_reference_data_pred['ref_date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:23.535988Z","iopub.execute_input":"2025-10-11T18:56:23.536361Z","iopub.status.idle":"2025-10-11T18:56:23.978963Z","shell.execute_reply.started":"2025-10-11T18:56:23.536337Z","shell.execute_reply":"2025-10-11T18:56:23.977562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history_reference_data_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:24.912321Z","iopub.execute_input":"2025-10-11T18:56:24.912648Z","iopub.status.idle":"2025-10-11T18:56:24.931722Z","shell.execute_reply.started":"2025-10-11T18:56:24.912625Z","shell.execute_reply":"2025-10-11T18:56:24.930514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## GeÃ§miÅŸ veriyi al","metadata":{}},{"cell_type":"code","source":"customer_history_reference_data_pred_gecmis = customer_history_reference_data_pred[customer_history_reference_data_pred['date'] < customer_history_reference_data_pred['ref_date']]\ncustomer_history_reference_data_pred_gecmis.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:27.630720Z","iopub.execute_input":"2025-10-11T18:56:27.631014Z","iopub.status.idle":"2025-10-11T18:56:27.886906Z","shell.execute_reply.started":"2025-10-11T18:56:27.630996Z","shell.execute_reply":"2025-10-11T18:56:27.886072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df_pred = customer_history_reference_data_pred[customer_history_reference_data_pred['ref_date'] == customer_history_reference_data_pred['date']]\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:29.828625Z","iopub.execute_input":"2025-10-11T18:56:29.828914Z","iopub.status.idle":"2025-10-11T18:56:29.876067Z","shell.execute_reply.started":"2025-10-11T18:56:29.828885Z","shell.execute_reply":"2025-10-11T18:56:29.874643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df_pred['age_group'] = filtered_df_pred['age'].apply(categorize_age)\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:32.400553Z","iopub.execute_input":"2025-10-11T18:56:32.400910Z","iopub.status.idle":"2025-10-11T18:56:32.428631Z","shell.execute_reply.started":"2025-10-11T18:56:32.400886Z","shell.execute_reply":"2025-10-11T18:56:32.427603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"column_mapping = {\n    'mobile_eft_all_cnt': 'avg_eft_cnt',\n    'mobile_eft_all_amt': 'avg_eft_amt',\n    'cc_transaction_all_amt': 'avg_cc_amt',\n    'cc_transaction_all_cnt': 'avg_cc_cnt',\n    'active_product_category_nbr': 'avg_active_products'\n}\n\n# SÃ¼tun isimlerini deÄŸiÅŸtir\nfiltered_df_pred = filtered_df_pred.rename(columns=column_mapping)\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:35.978906Z","iopub.execute_input":"2025-10-11T18:56:35.979307Z","iopub.status.idle":"2025-10-11T18:56:36.003019Z","shell.execute_reply.started":"2025-10-11T18:56:35.979260Z","shell.execute_reply":"2025-10-11T18:56:36.001987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df_pred = filtered_df_pred.drop(columns=['date'])\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:38.849375Z","iopub.execute_input":"2025-10-11T18:56:38.849728Z","iopub.status.idle":"2025-10-11T18:56:38.869832Z","shell.execute_reply.started":"2025-10-11T18:56:38.849704Z","shell.execute_reply":"2025-10-11T18:56:38.868811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------\n# 1. Date features\n# ----------------------\nfiltered_df_pred['ref_month'] = filtered_df_pred['ref_date'].dt.month\nfiltered_df_pred['ref_quarter'] = filtered_df_pred['ref_date'].dt.quarter\nfiltered_df_pred['ref_weekday'] = filtered_df_pred['ref_date'].dt.weekday\n\n# Tenure bucket\nfiltered_df_pred['tenure_bucket'] = filtered_df_pred['tenure'].apply(tenure_bucket)\n\n# ----------------------\n# 2. Financial trends (delta features)\n# ----------------------\npast_pred_df = customer_history_reference_data_pred_gecmis.copy()  # geÃ§miÅŸ veriyi kullanÄ±yoruz\npast_pred_df['months_diff'] = ((past_pred_df['ref_date'].dt.year - past_pred_df['date'].dt.year) * 12 +\n                               (past_pred_df['ref_date'].dt.month - past_pred_df['date'].dt.month))\n\n# Son 3 ay\nlast_3m_df = past_pred_df[past_pred_df['months_diff'] <= 3]\ntrend_3m_pred = last_3m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_last_3m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_last_3m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_last_3m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_last_3m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# 3-6 ay\nlast_6m_df = past_pred_df[(past_pred_df['months_diff'] > 3) & (past_pred_df['months_diff'] <= 6)]\ntrend_3_6m_pred = last_6m_df.groupby(['cust_id', 'ref_date']).agg(\n    avg_eft_cnt_3_6m=('mobile_eft_all_cnt', 'mean'),\n    avg_eft_amt_3_6m=('mobile_eft_all_amt', 'mean'),\n    avg_cc_amt_3_6m=('cc_transaction_all_amt', 'mean'),\n    avg_cc_cnt_3_6m=('cc_transaction_all_cnt', 'mean')\n).reset_index()\n\n# Merge trend features\nfiltered_df_pred = filtered_df_pred.merge(trend_3m_pred, on=['cust_id','ref_date'], how='left')\nfiltered_df_pred = filtered_df_pred.merge(trend_3_6m_pred, on=['cust_id','ref_date'], how='left')\n\n# Delta features\nfiltered_df_pred['delta_eft_cnt'] = filtered_df_pred['avg_eft_cnt_last_3m'] - filtered_df_pred['avg_eft_cnt_3_6m']\nfiltered_df_pred['delta_eft_amt'] = filtered_df_pred['avg_eft_amt_last_3m'] - filtered_df_pred['avg_eft_amt_3_6m']\nfiltered_df_pred['delta_cc_cnt'] = filtered_df_pred['avg_cc_cnt_last_3m'] - filtered_df_pred['avg_cc_cnt_3_6m']\nfiltered_df_pred['delta_cc_amt'] = filtered_df_pred['avg_cc_amt_last_3m'] - filtered_df_pred['avg_cc_amt_3_6m']\n\n# ----------------------\n# 3. Product diversity\n# ----------------------\nfiltered_df_pred['active_product_ratio'] = filtered_df_pred['has_cc'] / (filtered_df_pred['avg_active_products'] + 1e-6)\n\n# ----------------------\n# 4. Recency & frequency\n# ----------------------\nfiltered_df_pred['last_eft_months'] = filtered_df_pred['avg_eft_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\nfiltered_df_pred['last_cc_months'] = filtered_df_pred['avg_cc_cnt_last_3m'].apply(lambda x: 0 if x>0 else 3)\n\nfiltered_df_pred['total_trx_last_3m'] = filtered_df_pred['avg_eft_cnt_last_3m'] + filtered_df_pred['avg_cc_cnt_last_3m']\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:44.581699Z","iopub.execute_input":"2025-10-11T18:56:44.582031Z","iopub.status.idle":"2025-10-11T18:56:45.361352Z","shell.execute_reply.started":"2025-10-11T18:56:44.582007Z","shell.execute_reply":"2025-10-11T18:56:45.360331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df_pred['churn'] = 0 # for the dataprocessing purposes\nfiltered_df_pred = filtered_df_pred[summary_df.columns]\nfiltered_df_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:56:54.951352Z","iopub.execute_input":"2025-10-11T18:56:54.951713Z","iopub.status.idle":"2025-10-11T18:56:54.980222Z","shell.execute_reply.started":"2025-10-11T18:56:54.951686Z","shell.execute_reply":"2025-10-11T18:56:54.978840Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SUBMISSON","metadata":{}},{"cell_type":"code","source":"# ----------------------\n# 1. Feature set\n# ----------------------\ndrop_cols_pred = ['cust_id', 'ref_date', 'churn']  # churn zaten yok, yine gÃ¼venlik iÃ§in Ã§Ä±karÄ±yoruz\nX_pred = filtered_df_pred.drop(columns=drop_cols_pred)\n\n# ----------------------\n# 2. Prediction (0/1)\n# ----------------------\ny_prob_pred = final_model.predict_proba(X_pred)[:,1]\nfiltered_df_pred['churn'] = (y_prob_pred >= 0.29440).astype(int)\n\n# ----------------------\n# 3. Submission format (ref_date olmadan)\n# ----------------------\nsubmission_df = filtered_df_pred[['cust_id', 'churn']].copy()\nsubmission_df.reset_index(drop=True, inplace=True)\n\n# ----------------------\n# 4. CSV olarak kaydet (opsiyonel)\n# ----------------------\nsubmission_df.to_csv('churn_submission.csv', index=False)\n\nsubmission_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:33:51.130703Z","iopub.execute_input":"2025-10-11T19:33:51.131006Z","iopub.status.idle":"2025-10-11T19:33:51.300870Z","shell.execute_reply.started":"2025-10-11T19:33:51.130987Z","shell.execute_reply":"2025-10-11T19:33:51.299882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df['churn'].value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:33:52.616837Z","iopub.execute_input":"2025-10-11T19:33:52.617163Z","iopub.status.idle":"2025-10-11T19:33:52.626065Z","shell.execute_reply.started":"2025-10-11T19:33:52.617142Z","shell.execute_reply":"2025-10-11T19:33:52.624654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reference_data['churn'].value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:30:38.684689Z","iopub.execute_input":"2025-10-11T19:30:38.684986Z","iopub.status.idle":"2025-10-11T19:30:38.694973Z","shell.execute_reply.started":"2025-10-11T19:30:38.684967Z","shell.execute_reply":"2025-10-11T19:30:38.693968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:06:25.672794Z","iopub.execute_input":"2025-10-11T19:06:25.673161Z","iopub.status.idle":"2025-10-11T19:06:25.683976Z","shell.execute_reply.started":"2025-10-11T19:06:25.673139Z","shell.execute_reply":"2025-10-11T19:06:25.682583Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## .","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nimport shap\nimport optuna\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import linregress\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob, return_dict=False):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.69257, \"recall_at_10perc\": 0.18469, \"lift_at_10perc\": 1.84715}\n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        if return_dict: return {\"competition_metric\": 0, \"roc_auc\": 0.5, \"gini\": -1, \"recall\": 0, \"lift\": 0}\n        return 0 \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n    new_scores = {\"roc_auc\": roc_auc, \"recall\": recall_at_10perc, \"lift\": lift_at_10perc}\n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    final_score = (final_gini_score * score_weights[\"gini\"] + final_recall_score * score_weights[\"recall_at_10perc\"] + final_lift_score * score_weights[\"lift_at_10perc\"])\n    if return_dict: \n        return {\n            \"competition_metric\": final_score, \n            \"roc_auc\": new_scores[\"roc_auc\"],\n            \"gini\": new_scores[\"gini\"], \n            \"recall\": new_scores[\"recall\"], \n            \"lift\": new_scores[\"lift\"]\n        }\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE YENÄ° Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    history_cols_to_fill = customer_history.select_dtypes(include=np.number).columns.tolist()\n    customer_history[history_cols_to_fill] = customer_history[history_cols_to_fill].fillna(0)\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef calculate_trend(series):\n    y = series.values\n    x = np.arange(len(y))\n    if len(y) < 2 or np.var(y) == 0:\n        return 0\n    slope, _, _, _, _ = linregress(x, y)\n    return slope\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None):\n    print(f\"Ã–zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Dependent'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Retired'\n    \n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] < history['ref_date']].copy().sort_values(by=['cust_id', 'date'])\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['month_year'] = history['date'].dt.to_period('M')\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"Lag ve rolling Ã¶zellikler hesaplanÄ±yor...\")\n    history_pivoted = history.pivot_table(index='cust_id', columns='months_before_ref', values=['total_transaction_amt', 'total_transaction_cnt'])\n    history_pivoted.columns = [f'{col[0]}_lag_{col[1]}' for col in history_pivoted.columns]\n    lag_features_to_add = []\n    for lag in range(1, 4):\n        for col in ['total_transaction_amt', 'total_transaction_cnt']:\n            feature_name = f'{col}_lag_{lag}'\n            if feature_name not in history_pivoted.columns:\n                history_pivoted[feature_name] = 0\n            lag_features_to_add.append(feature_name)\n    df = pd.merge(df, history_pivoted[lag_features_to_add], on='cust_id', how='left')\n\n    aggs = {}\n    cols_to_agg = ['mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', 'cc_transaction_all_amt', 'total_transaction_amt', 'total_transaction_cnt']\n    for col in cols_to_agg:\n        aggs[col] = ['mean', 'sum', 'std', 'min', 'max', 'last']\n    aggs['date'] = ['nunique']\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    for window in [1, 3, 6, 12]:\n        period_history = history[history['months_before_ref'] <= window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"Ãœstel aÄŸÄ±rlÄ±klÄ± Ã¶zellikler hesaplanÄ±yor...\")\n    alpha = 0.90 \n    history['decay_weight'] = alpha ** history['months_before_ref']\n    for col in ['total_transaction_amt', 'total_transaction_cnt', 'active_product_category_nbr']:\n        history[f'weighted_{col}'] = history[col] * history['decay_weight']\n        weighted_sum = history.groupby('cust_id')[f'weighted_{col}'].sum()\n        weight_sum = history.groupby('cust_id')['decay_weight'].sum()\n        df[f'ewm_{col}'] = df['cust_id'].map(weighted_sum / (weight_sum + 1e-6))\n\n    print(\"Trend ve karÅŸÄ±laÅŸtÄ±rma Ã¶zellikleri hesaplanÄ±yor...\")\n    history_last_6m = history[history['months_before_ref'] <= 6]\n    for col in ['total_transaction_amt', 'total_transaction_cnt', 'active_product_category_nbr']:\n        trends = history_last_6m.groupby('cust_id')[col].apply(calculate_trend)\n        df[f'{col}_trend_6m'] = df['cust_id'].map(trends)\n    df['ratio_amt_mean_3m_6m'] = df['total_transaction_amt_mean_last_3m'] / (df['total_transaction_amt_mean_last_6m'] + 1e-6)\n    df['diff_amt_last_1m_vs_3m_avg'] = df['total_transaction_amt_sum_last_1m'] - df['total_transaction_amt_mean_last_3m']\n\n    print(\"Zaman dinamiÄŸi, RFM ve volatilite Ã¶zellikleri hesaplanÄ±yor...\")\n    history['days_between_transactions'] = history.groupby('cust_id')['date'].diff().dt.days\n    days_between_stats = history.groupby('cust_id')['days_between_transactions'].agg(['mean', 'std']).rename(columns={'mean': 'days_between_txn_mean', 'std': 'days_between_txn_std'})\n    df = pd.merge(df, days_between_stats, on='cust_id', how='left')\n    df['amt_coeff_variation_all'] = df['total_transaction_amt_std_all'] / (df['total_transaction_amt_mean_all'] + 1e-6)\n    df['cnt_coeff_variation_all'] = df['total_transaction_cnt_std_all'] / (df['total_transaction_cnt_mean_all'] + 1e-6)\n\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    df['transaction_frequency_all'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['avg_transaction_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['active_months_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    \n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n    \n    print(\"DavranÄ±ÅŸsal segmentasyon (KMeans) yapÄ±lÄ±yor...\")\n    cluster_cols = ['total_transaction_amt_mean_all', 'total_transaction_cnt_mean_all', 'active_months_ratio', 'transaction_frequency_all']\n    cluster_data = df[cluster_cols].fillna(0)\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['behavior_segment'] = kmeans.fit_predict(cluster_data)\n        kmeans_model = kmeans\n    else:\n        df['behavior_segment'] = kmeans_model.predict(cluster_data)\n        \n    print(\"EtkileÅŸim Ã¶zellikleri oluÅŸturuluyor...\")\n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['age_group_x_work_sector_x_behavior_segment'] = df['age_group'].astype(str) + '_' + df['work_sector'].astype(str) + '_' + df['behavior_segment'].astype(str)\n    df['gender_x_province_x_behavior_segment'] = df['gender'].astype(str) + '_' + df['province'].astype(str) + '_' + df['behavior_segment'].astype(str)\n\n    categorical_features = ['gender', 'province', 'religion', 'work_type', 'work_sector', 'age_group', 'tenure_group', 'behavior_segment', 'gender_x_age_group', 'tenure_group_x_work_sector', 'age_group_x_work_sector_x_behavior_segment', 'gender_x_province_x_behavior_segment']\n    for col in categorical_features:\n        if df[col].isnull().any():\n            mode_value = df[col].mode()[0]\n            df[col] = df[col].fillna(mode_value)\n        if not isinstance(df[col].dtype, pd.CategoricalDtype):\n             df[col] = df[col].astype('category')\n            \n    df = df.drop(columns=['last_transaction_date', 'first_transaction_date'], errors='ignore')\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model\n\n# =============================================================================\n# Ã‡OKLU DOÄžRUSALLIK KONTROLÃœ\n# =============================================================================\ndef remove_multicollinearity(df, features, threshold=0.90):\n    print(f\"Ã‡oklu doÄŸrusallÄ±k kontrolÃ¼ baÅŸlatÄ±lÄ±yor (eÅŸik = {threshold})...\")\n    numeric_df = df[features].select_dtypes(include=np.number)\n    corr_matrix = numeric_df.corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    print(f\"YÃ¼ksek korelasyon nedeniyle {len(to_drop)} Ã¶zellik kaldÄ±rÄ±lacak.\")\n    return to_drop\n\n# =============================================================================\n# SHAP ile Ã–zellik SeÃ§imi\n# =============================================================================\ndef feature_selection_with_shap(train_df, features, target, n_features=300):\n    print(f\"SHAP ile en iyi {n_features} Ã¶zelliÄŸin seÃ§imi baÅŸlÄ±yor...\")\n    X_train, y_train = train_df[features].copy(), train_df[target]\n    for col in X_train.select_dtypes(include=['category']).columns:\n        X_train[col] = X_train[col].cat.codes\n\n    lgb_params = {'objective': 'binary', 'metric': 'auc', 'seed': 42, 'n_jobs': -1, 'verbose': -1}\n    model = lgb.LGBMClassifier(**lgb_params)\n    model.fit(X_train, y_train)\n    \n    try:\n        import shap\n    except ImportError:\n        print(\"SHAP kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. LÃ¼tfen `pip install shap` ile yÃ¼kleyin.\")\n        return features\n\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_train)\n    \n    if isinstance(shap_values, list):\n        shap_values_to_use = shap_values[1]\n    else:\n        shap_values_to_use = shap_values\n\n    mean_abs_shap = np.abs(shap_values_to_use).mean(axis=0)\n    feature_importance_df = pd.DataFrame({'feature': features, 'shap_importance': mean_abs_shap})\n    feature_importance_df = feature_importance_df.sort_values(by='shap_importance', ascending=False)\n    \n    top_features = feature_importance_df['feature'].head(n_features).tolist()\n    print(f\"{n_features} en Ã¶nemli Ã¶zellik seÃ§ildi.\")\n    \n    return top_features\n\n# =============================================================================\n# Optuna ile Optimizasyon ve Final Model EÄŸitimi\n# =============================================================================\ndef optimize_and_train_lightgbm(train_df, test_df, selected_features, sample_submission_df, n_trials_optuna=15):\n    print(\"Optuna ile LightGBM optimizasyonu ve eÄŸitimi baÅŸlÄ±yor...\")\n    target = 'churn'\n    \n    numerical_features = [f for f in selected_features if not isinstance(train_df[f].dtype, pd.CategoricalDtype)]\n    scaler = StandardScaler()\n    train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])\n    test_df[numerical_features] = scaler.transform(test_df[numerical_features])\n    print(\"SayÄ±sal Ã¶zelliklere Z-Score normalizasyonu uygulandÄ±.\")\n\n    X_train, y_train = train_df[selected_features], train_df[target]\n    X_test = test_df[selected_features]\n    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n    categorical_features_in_model = [col for col in selected_features if isinstance(X_train[col].dtype, pd.CategoricalDtype)]\n\n    def objective(trial):\n        params = {\n            'objective': 'binary', 'metric': 'auc', 'scale_pos_weight': scale_pos_weight, \n            'n_estimators': 1000, \n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05), \n            'num_leaves': trial.suggest_int('num_leaves', 20, 100), \n            'max_depth': trial.suggest_int('max_depth', 5, 12), \n            'subsample': trial.suggest_float('subsample', 0.6, 1.0), \n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0), \n            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0), \n            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0), \n            'seed': 42, 'n_jobs': -1, 'verbose': -1\n        }\n        \n        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n        all_fold_metrics = []\n        for train_idx, val_idx in skf.split(X_train, y_train):\n            X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n            X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n            \n            model = lgb.LGBMClassifier(**params)\n            model.fit(X_train_fold, y_train_fold, \n                      eval_set=[(X_val_fold, y_val_fold)], \n                      categorical_feature=categorical_features_in_model,\n                      callbacks=[lgb.early_stopping(50, verbose=False)])\n            \n            preds = model.predict_proba(X_val_fold)[:, 1]\n            fold_metrics = ing_hubs_datathon_metric(y_val_fold, preds, return_dict=True)\n            all_fold_metrics.append(fold_metrics)\n            \n        avg_metrics = pd.DataFrame(all_fold_metrics).mean().to_dict()\n        trial.set_user_attr(\"roc_auc\", avg_metrics[\"roc_auc\"])\n        trial.set_user_attr(\"gini\", avg_metrics[\"gini\"]); trial.set_user_attr(\"recall\", avg_metrics[\"recall\"]); trial.set_user_attr(\"lift\", avg_metrics[\"lift\"])\n        return avg_metrics[\"competition_metric\"]\n\n    print(f\"\\n--- LightGBM Optimizasyonu ({n_trials_optuna} deneme) ---\")\n    study_lgbm = optuna.create_study(direction='maximize')\n    study_lgbm.optimize(objective, n_trials=n_trials_optuna)\n    best_params_lgbm = study_lgbm.best_params\n\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu.\")\n    print(\"LGBM Best Params:\", best_params_lgbm)\n\n    print(\"\\nEn iyi parametrelerle final LightGBM modeli eÄŸitiliyor...\")\n    final_lgbm_params = {\n        'objective': 'binary', 'metric': 'auc', 'scale_pos_weight': scale_pos_weight, \n        'n_estimators': 5000, 'random_state': 42, 'n_jobs': -1, 'verbose': -1,\n        **best_params_lgbm\n    }\n    \n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    test_preds_lgbm = np.zeros(len(X_test))\n    oof_metrics_lgbm = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n        print(f\"===== Fold {fold+1} =====\")\n        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n        \n        lgbm = lgb.LGBMClassifier(**final_lgbm_params)\n        lgbm.fit(X_train_fold, y_train_fold, \n                 eval_set=[(X_val_fold, y_val_fold)], \n                 categorical_feature=categorical_features_in_model,\n                 callbacks=[lgb.early_stopping(150, verbose=False)])\n        \n        test_preds_lgbm += lgbm.predict_proba(X_test)[:, 1] / skf.n_splits\n        oof_metrics_lgbm.append(ing_hubs_datathon_metric(y_val_fold, lgbm.predict_proba(X_val_fold)[:, 1], return_dict=True))\n        gc.collect()\n        \n    mean_metrics_lgbm = pd.DataFrame(oof_metrics_lgbm).mean()\n    print(\"\\n==============================================\")\n    print(f\"LGBM CV Skoru: {mean_metrics_lgbm['competition_metric']:.4f} (Gini: {mean_metrics_lgbm['gini']:.4f}, Recall: {mean_metrics_lgbm['recall']:.4f}, Lift: {mean_metrics_lgbm['lift']:.4f})\")\n    print(\"==============================================\")\n    \n    final_preds = test_preds_lgbm\n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = final_preds\n    submission_df.to_csv('submission_lgbm_final_optimized.csv', index=False)\n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_lgbm_final_optimized.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model)\n    \n    del customer_history, customers, train_ref, test_ref; gc.collect()\n    \n    common_cols = list(set(train_featured.columns) & set(test_featured.columns))\n    features_to_drop_initial = ['cust_id', 'ref_date', 'churn']\n    all_features = [col for col in common_cols if col not in features_to_drop_initial]\n    target = 'churn'\n    \n    highly_correlated_features = remove_multicollinearity(train_featured, all_features, threshold=0.90)\n    all_features_filtered = [f for f in all_features if f not in highly_correlated_features]\n    print(f\"Ã‡oklu doÄŸrusallÄ±k kontrolÃ¼ sonrasÄ± kalan Ã¶zellik sayÄ±sÄ±: {len(all_features_filtered)}\")\n\n    selected_features = feature_selection_with_shap(train_featured, all_features_filtered, target, n_features=300)\n    \n    submission = optimize_and_train_lightgbm(train_featured, test_featured, selected_features, sample_submission, n_trials_optuna=15)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T14:01:26.569290Z","iopub.execute_input":"2025-10-14T14:01:26.569657Z","iopub.status.idle":"2025-10-14T14:08:20.941193Z","shell.execute_reply.started":"2025-10-14T14:01:26.569628Z","shell.execute_reply":"2025-10-14T14:08:20.939715Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ******","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:28.428159Z","iopub.execute_input":"2025-10-15T16:56:28.428933Z","iopub.status.idle":"2025-10-15T16:56:28.434059Z","shell.execute_reply.started":"2025-10-15T16:56:28.428906Z","shell.execute_reply":"2025-10-15T16:56:28.433040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ncustomer_history = pd.read_csv(\"/kaggle/input/ing-hackathon-data/customer_history.csv\")\ncustomers = pd.read_csv(\"/kaggle/input/ing-hackathon-data/customers.csv\")\nreference_data= pd.read_csv(\"/kaggle/input/ing-hackathon-data/referance_data.csv\")\nreference_data_test = pd.read_csv(\"/kaggle/input/ing-hackathon-data/referance_data_test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/ing-hackathon-data/sample_submission.csv\")\n\nprint(\"ðŸ“Š VERÄ° SETÄ° BOYUTLARI:\")\nprint(f\"customer_history: {customer_history.shape}\")\nprint(f\"customers: {customers.shape}\")\nprint(f\"reference_data: {reference_data.shape}\")\nprint(f\"reference_data_test: {reference_data_test.shape}\")\nprint(f\"sample_submission: {sample_submission.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:29.487959Z","iopub.execute_input":"2025-10-15T16:56:29.488427Z","iopub.status.idle":"2025-10-15T16:56:37.119574Z","shell.execute_reply.started":"2025-10-15T16:56:29.488392Z","shell.execute_reply":"2025-10-15T16:56:37.118212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customer_history.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:38:32.585510Z","iopub.execute_input":"2025-10-14T18:38:32.585858Z","iopub.status.idle":"2025-10-14T18:38:32.616511Z","shell.execute_reply.started":"2025-10-14T18:38:32.585832Z","shell.execute_reply":"2025-10-14T18:38:32.615722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"customers.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:38:34.225232Z","iopub.execute_input":"2025-10-14T18:38:34.225850Z","iopub.status.idle":"2025-10-14T18:38:34.236643Z","shell.execute_reply.started":"2025-10-14T18:38:34.225822Z","shell.execute_reply":"2025-10-14T18:38:34.235908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df = pd.merge(customer_history, customers, on='cust_id')\ncust_hist_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:43.322054Z","iopub.execute_input":"2025-10-15T16:56:43.322463Z","iopub.status.idle":"2025-10-15T16:56:44.487063Z","shell.execute_reply.started":"2025-10-15T16:56:43.322435Z","shell.execute_reply":"2025-10-15T16:56:44.486048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df.loc[\n    (cust_hist_df['work_type'] == 'Student') & (cust_hist_df['work_sector'].isnull()),\n    'work_sector'\n] = 'Student'\n\n# KoÅŸul 2: work_type 'Retired' ise, work_sector'daki NaN deÄŸerleri 'Pension' yap.\ncust_hist_df.loc[\n    (cust_hist_df['work_type'] == 'Retired') & (cust_hist_df['work_sector'].isnull()),\n    'work_sector'\n] = 'Pension'\n\n# KoÅŸul 3: work_type 'Unemployed' ise, work_sector'daki NaN deÄŸerleri 'Unemployed' yap.\ncust_hist_df.loc[\n    (cust_hist_df['work_type'] == 'Unemployed') & (cust_hist_df['work_sector'].isnull()),\n    'work_sector'\n] = 'Unemployed'\ncust_hist_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:49.097645Z","iopub.execute_input":"2025-10-15T16:56:49.097979Z","iopub.status.idle":"2025-10-15T16:56:51.084617Z","shell.execute_reply.started":"2025-10-15T16:56:49.097956Z","shell.execute_reply":"2025-10-15T16:56:51.083466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\ncust_hist_df['has_eft'] = np.where(cust_hist_df['mobile_eft_all_amt'].notnull(), 1, 0)\ncust_hist_df['has_cc_transaction'] = np.where(cust_hist_df['cc_transaction_all_amt'].notnull(), 1, 0)\ncolumns_to_fill = [\n    'mobile_eft_all_cnt',\n    'mobile_eft_all_amt',\n    'cc_transaction_all_amt',\n    'cc_transaction_all_cnt'\n]\ncust_hist_df[columns_to_fill] = cust_hist_df[columns_to_fill].fillna(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:55.775972Z","iopub.execute_input":"2025-10-15T16:56:55.776378Z","iopub.status.idle":"2025-10-15T16:56:56.126419Z","shell.execute_reply.started":"2025-10-15T16:56:55.776355Z","shell.execute_reply":"2025-10-15T16:56:56.125114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:56:57.975758Z","iopub.execute_input":"2025-10-15T16:56:57.976883Z","iopub.status.idle":"2025-10-15T16:56:57.996535Z","shell.execute_reply.started":"2025-10-15T16:56:57.976847Z","shell.execute_reply":"2025-10-15T16:56:57.995195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bins = [17, 30, 45, 64, np.inf]  # saÄŸ sÄ±nÄ±rlar dahil olacak ÅŸekilde\nlabels = ['young_adults', 'est_adults', 'prime_age', 'senior']\ncust_hist_df['age_group'] = pd.cut(cust_hist_df['age'], bins=bins, labels=labels, right=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:57:02.103980Z","iopub.execute_input":"2025-10-15T16:57:02.104836Z","iopub.status.idle":"2025-10-15T16:57:02.227385Z","shell.execute_reply.started":"2025-10-15T16:57:02.104700Z","shell.execute_reply":"2025-10-15T16:57:02.226030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"monthly_cust_counts = cust_hist_df.groupby(\"date\")[\"cust_id\"].nunique().reset_index()\nmonthly_cust_counts.columns = [\"date\", \"unique_cust_count\"]\nmonthly_cust_counts.head(50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T16:57:04.585869Z","iopub.execute_input":"2025-10-15T16:57:04.586262Z","iopub.status.idle":"2025-10-15T16:57:05.836706Z","shell.execute_reply.started":"2025-10-15T16:57:04.586234Z","shell.execute_reply":"2025-10-15T16:57:05.835528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:38:59.985974Z","iopub.execute_input":"2025-10-14T18:38:59.986246Z","iopub.status.idle":"2025-10-14T18:39:00.002524Z","shell.execute_reply.started":"2025-10-14T18:38:59.986226Z","shell.execute_reply":"2025-10-14T18:39:00.001598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"def create_tenure_segments(df):\n    df_copy = df.copy()\n    \n    # MÃ¼ÅŸteri yaÅŸam dÃ¶ngÃ¼sÃ¼ segmentleri\n    df_copy['tenure_lifecycle'] = pd.cut(\n        df_copy['tenure'],\n        bins=[0, 6, 12, 24, 36, 60, float('inf')],\n        labels=['0-6_ay_cok_yeni', '6-12_ay_yeni', '1-2_yil_orta', '2-3_yil_deneyimli', '3-5_yil_sadik', '5+yil_cok_sadik']\n    )\n    \n    return df_copy\ndef create_functional_features(df):\n    df_copy = df.copy()\n    \n    # 1. Transaction intensity - aylÄ±k ortalama iÅŸlem yoÄŸunluÄŸu\n    df_copy['transaction_intensity'] = (\n        df_copy['mobile_eft_all_cnt'] + df_copy['cc_transaction_all_cnt']\n    ) / df_copy['tenure']\n    \n    # NaN ve sonsuz deÄŸerleri temizle\n    df_copy['transaction_intensity'] = df_copy['transaction_intensity'].replace([np.inf, -np.inf], np.nan)\n    df_copy['transaction_intensity'] = df_copy['transaction_intensity'].fillna(0)\n    \n    # 2. AylÄ±k mÃ¼ÅŸteri deÄŸeri\n    df_copy['customer_value_per_month'] = (\n        df_copy['mobile_eft_all_amt'] + df_copy['cc_transaction_all_amt']\n    ) / df_copy['tenure']\n    \n    df_copy['customer_value_per_month'] = df_copy['customer_value_per_month'].replace([np.inf, -np.inf], np.nan)\n    df_copy['customer_value_per_month'] = df_copy['customer_value_per_month'].fillna(0)\n    \n    # 3. Tenure/age oranÄ±\n    df_copy['tenure_age_ratio'] = df_copy['tenure'] / df_copy['age']\n    df_copy['tenure_age_ratio'] = df_copy['tenure_age_ratio'].replace([np.inf, -np.inf], np.nan)\n    df_copy['tenure_age_ratio'] = df_copy['tenure_age_ratio'].fillna(0)\n    \n    # 4. YaÅŸa gÃ¶re normalize tenure\n    df_copy['tenure_relative_to_age'] = df_copy['tenure'] / (df_copy['age'] * 12)\n    df_copy['tenure_relative_to_age'] = df_copy['tenure_relative_to_age'].replace([np.inf, -np.inf], np.nan)\n    df_copy['tenure_relative_to_age'] = df_copy['tenure_relative_to_age'].fillna(0)\n    \n    # 5. Tenure risk segmentleri\n    conditions = [\n        (df_copy['tenure'] <= 12) & (df_copy['age'] >= 50),\n        (df_copy['tenure'] <= 12) & (df_copy['age'] < 50),\n        (df_copy['tenure'] > 60) & (df_copy['age'] >= 50),\n        (df_copy['tenure'] > 60) & (df_copy['age'] < 50)\n    ]\n    choices = ['risk_short_tenure_senior', 'risk_short_tenure_young', \n               'stable_long_tenure_senior', 'stable_long_tenure_young']\n    df_copy['tenure_risk_segment'] = np.select(conditions, choices, default='standard')\n    \n    return df_copy\n\ndef create_transaction_diversity_features(df):\n    df_new = df.copy()\n    \n    # Toplam iÅŸlem sayÄ±sÄ±\n    df_new['total_transaction_count'] = df_new['mobile_eft_all_cnt'] + df_new['cc_transaction_all_cnt']\n    \n    # Toplam iÅŸlem tutarÄ±\n    df_new['total_transaction_amount'] = df_new['mobile_eft_all_amt'] + df_new['cc_transaction_all_amt']\n    \n    # Ä°ÅŸlem tÃ¼rÃ¼ Ã§eÅŸitliliÄŸi (EFT ve kredi kartÄ± iÅŸlemi yapÄ±p yapmadÄ±ÄŸÄ±)\n    df_new['has_both_transaction_types'] = ((df_new['mobile_eft_all_cnt'] > 0) & (df_new['cc_transaction_all_cnt'] > 0)).astype(int)\n    \n    # Ortalama iÅŸlem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ (tÃ¼m iÅŸlemler iÃ§in)\n    df_new['overall_avg_transaction_size'] = df_new['total_transaction_amount'] / df_new['total_transaction_count']\n    df_new['overall_avg_transaction_size'] = df_new['overall_avg_transaction_size'].replace([np.inf, -np.inf], 0)\n    \n    return df_new\n\ndef create_time_based_features(df):\n    df_new = df.copy()\n    \n    # MÃ¼ÅŸterinin aylÄ±k ortalama iÅŸlem sayÄ±sÄ±\n    df_new['monthly_avg_transaction_count'] = df_new['total_transaction_count'] / df_new['tenure']\n    \n    # MÃ¼ÅŸterinin aylÄ±k ortalama iÅŸlem tutarÄ±\n    df_new['monthly_avg_transaction_amount'] = df_new['total_transaction_amount'] / df_new['tenure']\n    \n    # Tenure'a gÃ¶re Ã¼rÃ¼n kategorisi deÄŸiÅŸimi (std zaten alÄ±nÄ±yor ama burada farklÄ± bir Ã¶zellik)\n    # Burada her mÃ¼ÅŸterinin tenure'Ä±na gÃ¶re aylÄ±k ortalama iÅŸlem tutarÄ± ve sayÄ±sÄ± hesaplanÄ±yor.\n    # Zaten tenure bazlÄ± ortalamalarÄ± alÄ±yorsunuz, bu yÃ¼zden bu feature'larÄ± ekliyorum.\n    \n    return df_new\n\ndef create_customer_value_features(df):\n    df_new = df.copy()\n    \n    # MÃ¼ÅŸteri deÄŸer segmenti (total_transaction_amount ve tenure kullanarak)\n    df_new['customer_value_score'] = df_new['total_transaction_amount'] / df_new['tenure']\n    \n    # Ä°ÅŸlem sÄ±klÄ±ÄŸÄ± (toplam iÅŸlem sayÄ±sÄ±nÄ±n tenure'a oranÄ±)\n    df_new['transaction_frequency'] = df_new['total_transaction_count'] / df_new['tenure']\n    \n    # ÃœrÃ¼n kullanÄ±m yoÄŸunluÄŸu (active_product_category_nbr / tenure)\n    df_new['product_usage_intensity'] = df_new['active_product_category_nbr'] / df_new['tenure']\n    \n    return df_new\n\ndef create_risk_segmentation_features(df):\n    df_new = df.copy()\n    \n    # YaÅŸ ve tenure'a gÃ¶re risk segmentleri\n    conditions = [\n        (df_new['tenure'] < 12) & (df_new['age'] < 30),\n        (df_new['tenure'] < 12) & (df_new['age'] >= 30),\n        (df_new['tenure'] >= 12) & (df_new['tenure'] < 24) & (df_new['age'] < 30),\n        (df_new['tenure'] >= 12) & (df_new['tenure'] < 24) & (df_new['age'] >= 30),\n        (df_new['tenure'] >= 24) & (df_new['age'] < 30),\n        (df_new['tenure'] >= 24) & (df_new['age'] >= 30)\n    ]\n    choices = ['very_young_new', 'older_new', 'young_established', 'older_established', 'young_loyal', 'older_loyal']\n    df_new['age_tenure_segment'] = np.select(conditions, choices, default='other')\n    \n    # Ä°ÅŸlem tutarlÄ±lÄ±k puanÄ± (std'ler zaten alÄ±nÄ±yor, burada farklÄ± bir metrik)\n    # Ã–rneÄŸin, iÅŸlem sayÄ±larÄ±nÄ±n tenure'a oranÄ± ile tutarlÄ±lÄ±k\n    df_new['transaction_consistency_score'] = (df_new['mobile_eft_all_cnt'] + df_new['cc_transaction_all_cnt']) / (df_new['tenure'] + 1)\n    \n    return df_new\n\n\ndef create_temporal_trend_features(df):\n    df_new = df.copy()\n    \n    # Zaman trend Ã¶zellikleri\n    df_new['transaction_velocity_3m'] = df_new['mobile_eft_all_cnt'] / 3\n    df_new['transaction_velocity_6m'] = df_new['mobile_eft_all_cnt'] / 6\n    \n    # Ãœstel aÄŸÄ±rlÄ±klÄ± hareketli ortalama benzeri\n    df_new['weighted_transaction_importance'] = df_new['mobile_eft_all_amt'] * (0.9 ** df_new['tenure'])\n    \n    return df_new\n\ndef create_comparison_ratio_features(df):\n    df_new = df.copy()\n    \n    # DÃ¶nem karÅŸÄ±laÅŸtÄ±rma oranlarÄ±\n    df_new['transaction_growth_3m_vs_6m'] = df_new['mobile_eft_all_amt_mean_last_3m'] / (df_new['mobile_eft_all_amt_mean_last_6m'] + 1e-6)\n    df_new['activity_growth_3m_vs_6m'] = df_new['mobile_eft_all_cnt_mean_last_3m'] / (df_new['mobile_eft_all_cnt_mean_last_6m'] + 1e-6)\n    \n    # Son ay vs ortalamalar\n    df_new['recent_activity_vs_avg'] = df_new['mobile_eft_all_cnt_sum_last_1m'] / (df_new['mobile_eft_all_cnt_mean_last_3m'] + 1e-6)\n    \n    return df_new\n\ndef create_volatility_consistency_features(df):\n    df_new = df.copy()\n    \n    # Ä°ÅŸlem tutarlÄ±lÄ±k katsayÄ±larÄ±\n    df_new['amount_consistency_score'] = 1 / (1 + df_new['mobile_eft_all_amt_std_all'])\n    df_new['frequency_consistency_score'] = 1 / (1 + df_new['mobile_eft_all_cnt_std_all'])\n    \n    # DeÄŸiÅŸkenlik katsayÄ±larÄ±\n    df_new['amount_coefficient_variation'] = df_new['mobile_eft_all_amt_std_all'] / (df_new['mobile_eft_all_amt_mean_all'] + 1e-6)\n    df_new['frequency_coefficient_variation'] = df_new['mobile_eft_all_cnt_std_all'] / (df_new['mobile_eft_all_cnt_mean_all'] + 1e-6)\n    \n    return df_new\ndef create_interaction_features(df):\n    \"\"\"\n    Ã–nemli olabilecek deÄŸiÅŸkenler arasÄ±nda etkileÅŸim Ã¶zellikleri oluÅŸturur.\n    Bu, modelin daha karmaÅŸÄ±k iliÅŸkileri yakalamasÄ±na yardÄ±mcÄ± olur.\n    \"\"\"\n    df_new = df.copy()\n    \n    # MÃ¼ÅŸteri sadakati ve demografik etkileÅŸimleri\n    df_new['age_x_tenure'] = df_new['age'] * df_new['tenure']\n    \n    # Harcama alÄ±ÅŸkanlÄ±klarÄ± ve aktif Ã¼rÃ¼n sayÄ±sÄ± etkileÅŸimi\n    df_new['avg_transaction_x_product_count'] = (df_new['mobile_eft_all_amt'] + df_new['cc_transaction_all_amt']) / (df_new['active_product_category_nbr'] + 1)\n    \n    # MÃ¼ÅŸteri tenure'Ä± ile aylÄ±k iÅŸlem sayÄ±sÄ±nÄ±n etkileÅŸimi\n    df_new['tenure_x_monthly_transactions'] = df_new['tenure'] * ((df_new['mobile_eft_all_cnt'] + df_new['cc_transaction_all_cnt']) / 12)\n\n    return df_new\n\ndef create_enhanced_rfm_features(df):\n    \"\"\"GeliÅŸmiÅŸ RFM feature'larÄ±\"\"\"\n    df_new = df.copy()\n    \n    # Recency - Son iÅŸlemden bu yana geÃ§en sÃ¼re (tenure Ã¼zerinden)\n    df_new['recency_score'] = 1 / (1 + df_new['tenure'])\n    \n    # Frequency - Ä°ÅŸlem sÄ±klÄ±ÄŸÄ±\n    df_new['frequency_score'] = (df_new['mobile_eft_all_cnt'] + df_new['cc_transaction_all_cnt']) / df_new['tenure']\n    \n    # Monetary - Ä°ÅŸlem bÃ¼yÃ¼klÃ¼ÄŸÃ¼\n    df_new['monetary_score'] = (df_new['mobile_eft_all_amt'] + df_new['cc_transaction_all_amt']) / df_new['tenure']\n    \n    # RFM Segmentleri\n    df_new['rfm_segment'] = pd.cut(\n        df_new['recency_score'] * df_new['frequency_score'] * df_new['monetary_score'],\n        bins=5,\n        labels=['very_low', 'low', 'medium', 'high', 'very_high']\n    )\n    \n    # RFM Skoru\n    df_new['rfm_score'] = (\n        pd.qcut(df_new['recency_score'], 5, labels=[1, 2, 3, 4, 5]).astype(int) +\n        pd.qcut(df_new['frequency_score'], 5, labels=[1, 2, 3, 4, 5]).astype(int) + \n        pd.qcut(df_new['monetary_score'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n    )\n    \n    return df_new\n\ndef create_advanced_temporal_features1(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    date ve ref_date kullanarak zaman bazlÄ± (recency, trend, periyot) Ã¶zellikler Ã¼retir.\n    Bu fonksiyon, ana gruplama (aggregation) iÅŸleminden Ã–NCE Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r.\n    \"\"\"\n    print(\"-> GeliÅŸmiÅŸ zaman bazlÄ± Ã¶zellikler Ã¼retiliyor...\")\n    df_new = df.copy()\n\n    df_new['date'] = pd.to_datetime(df_new['date'])\n    df_new['ref_date'] = pd.to_datetime(df_new['ref_date'])\n    df_new = df_new.sort_values(by=['cust_id', 'date'])\n\n    df_new['days_before_ref'] = (df_new['ref_date'] - df_new['date']).dt.days\n    df_new['days_since_previous_transaction'] = df_new.groupby('cust_id')['date'].diff().dt.days.fillna(0)\n\n    total_transaction_amount = df_new['mobile_eft_all_amt'].fillna(0) + df_new['cc_transaction_all_amt'].fillna(0)\n    total_transaction_count = df_new['mobile_eft_all_cnt'].fillna(0) + df_new['cc_transaction_all_cnt'].fillna(0)\n\n    df_new['amt_last_30d'] = np.where(df_new['days_before_ref'] <= 30, total_transaction_amount, 0)\n    df_new['cnt_last_30d'] = np.where(df_new['days_before_ref'] <= 30, total_transaction_count, 0)\n    df_new['amt_last_90d'] = np.where(df_new['days_before_ref'] <= 90, total_transaction_amount, 0)\n    df_new['cnt_last_90d'] = np.where(df_new['days_before_ref'] <= 90, total_transaction_count, 0)\n\n    return df_new\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:13:59.230754Z","iopub.execute_input":"2025-10-15T18:13:59.231084Z","iopub.status.idle":"2025-10-15T18:13:59.266331Z","shell.execute_reply.started":"2025-10-15T18:13:59.231062Z","shell.execute_reply":"2025-10-15T18:13:59.264900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df =create_tenure_segments(cust_hist_df)\ncust_hist_df =create_functional_features(cust_hist_df)\ncust_hist_df = create_transaction_diversity_features(cust_hist_df)\ncust_hist_df = create_time_based_features(cust_hist_df)\ncust_hist_df = create_customer_value_features(cust_hist_df)\ncust_hist_df = create_risk_segmentation_features(cust_hist_df)\ncust_hist_df = create_temporal_trend_features(cust_hist_df)\ncust_hist_df = create_interaction_features(cust_hist_df)\ncust_hist_df = create_enhanced_rfm_features(cust_hist_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:00.616853Z","iopub.execute_input":"2025-10-15T18:14:00.617277Z","iopub.status.idle":"2025-10-15T18:14:26.690512Z","shell.execute_reply.started":"2025-10-15T18:14:00.617252Z","shell.execute_reply":"2025-10-15T18:14:26.689280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cust_hist_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:29.309455Z","iopub.execute_input":"2025-10-15T18:14:29.309866Z","iopub.status.idle":"2025-10-15T18:14:29.351030Z","shell.execute_reply.started":"2025-10-15T18:14:29.309840Z","shell.execute_reply":"2025-10-15T18:14:29.350022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train_test\nmerged_train_df = pd.merge(cust_hist_df, reference_data, on=\"cust_id\", how=\"inner\")\nmerged_test_df = pd.merge(cust_hist_df, reference_data_test, on=\"cust_id\", how=\"inner\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:32.429731Z","iopub.execute_input":"2025-10-15T18:14:32.430197Z","iopub.status.idle":"2025-10-15T18:14:36.354308Z","shell.execute_reply.started":"2025-10-15T18:14:32.430167Z","shell.execute_reply":"2025-10-15T18:14:36.353260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_train = merged_train_df\nfiltered_test = merged_test_df\n#filtered_train\n#filtred_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:45.404841Z","iopub.execute_input":"2025-10-15T18:14:45.405260Z","iopub.status.idle":"2025-10-15T18:14:45.410044Z","shell.execute_reply.started":"2025-10-15T18:14:45.405236Z","shell.execute_reply":"2025-10-15T18:14:45.408802Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"FEATURE-ENG2","metadata":{}},{"cell_type":"code","source":"filtered_train = create_advanced_temporal_features1(filtered_train)\nfiltered_test = create_advanced_temporal_features1(filtered_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:47.190898Z","iopub.execute_input":"2025-10-15T18:14:47.191954Z","iopub.status.idle":"2025-10-15T18:14:53.673473Z","shell.execute_reply.started":"2025-10-15T18:14:47.191915Z","shell.execute_reply":"2025-10-15T18:14:53.672541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop edilecek sÃ¼tunlarÄ± belirliyoruz\ndrop_cols = ['date', 'ref_date']\n\n# Yeni bir DataFrame oluÅŸturup sÃ¼tunlarÄ± Ã§Ä±karÄ±yoruz\nX_train = filtered_train.drop(columns=drop_cols)\nX_test = filtered_test.drop(columns=drop_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:14:54.641774Z","iopub.execute_input":"2025-10-15T18:14:54.642203Z","iopub.status.idle":"2025-10-15T18:14:55.908333Z","shell.execute_reply.started":"2025-10-15T18:14:54.642179Z","shell.execute_reply":"2025-10-15T18:14:55.907350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_train.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T17:48:43.184583Z","iopub.execute_input":"2025-10-15T17:48:43.184922Z","iopub.status.idle":"2025-10-15T17:48:43.234959Z","shell.execute_reply.started":"2025-10-15T17:48:43.184901Z","shell.execute_reply":"2025-10-15T17:48:43.233538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cust_id'ye gÃ¶re gruplayarak ortalamalarÄ± ve standart sapmalarÄ± alalÄ±m\nX_train_aggregated = X_train.groupby('cust_id').agg({\n    # Numeric deÄŸiÅŸkenlerin ortalamasÄ± ve standart sapmasÄ±\n    'mobile_eft_all_cnt': ['mean','std','min','max'],\n    'active_product_category_nbr': ['mean','std','min','max'],\n    'mobile_eft_all_amt': ['mean','min','std','max'],\n    'cc_transaction_all_amt': ['mean','min','std','max'],\n    'cc_transaction_all_cnt': ['mean','min','std','max'],\n    \n    # Demografik deÄŸiÅŸkenleri koru (first kullanarak ilk deÄŸeri al)\n    'gender': 'first',\n    'age': 'first',\n    'province': 'first',\n    'religion': 'first',\n    'work_type': 'first',\n    'work_sector': 'first',\n    'tenure': 'first',\n    'has_eft': 'first',\n    'has_cc_transaction': 'first',\n    'age_group': 'first',\n    'churn': 'first',\n\n    # tenure related\n    'tenure_lifecycle':'first',\n    'transaction_intensity':'mean',\n    'customer_value_per_month':'mean',\n    'tenure_age_ratio':'mean',\n    'tenure_relative_to_age':'mean',\n    'tenure_risk_segment':'first',\n    #\n    'total_transaction_count':'mean',\n    'total_transaction_amount':'mean',\n    'has_both_transaction_types':'first',\n    'overall_avg_transaction_size':'mean',\n    'monthly_avg_transaction_count':'mean',\n    'monthly_avg_transaction_amount':'mean',\n    'transaction_frequency':'mean',\n    'product_usage_intensity':'mean',\n    'age_tenure_segment':'first',\n    'transaction_consistency_score':'mean',\n    #\n    'age_x_tenure':'mean',\n    'avg_transaction_x_product_count':'mean',\n    'tenure_x_monthly_transactions':'mean',\n    #\n    'recency_score':\"mean\",\n    'frequency_score':\"mean\",\n    'monetary_score':\"mean\",\n    'rfm_segment':\"first\",\n    'rfm_score':'mean',\n    #\n    'days_before_ref':'mean',\n    'days_since_previous_transaction':'mean',\n    'amt_last_30d':'mean',\n    'cnt_last_30d':'mean',\n    'amt_last_90d':'mean',\n    'cnt_last_90d':'mean'\n    \n\n    \n}).reset_index()\n\n# Column isimlerini dÃ¼zelt\nX_train_aggregated.columns = ['_'.join(col).strip() if col[1] != 'first' else col[0] for col in X_train_aggregated.columns]\nX_train_aggregated = X_train_aggregated.rename(columns={'cust_id_': 'cust_id'})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:15:38.111959Z","iopub.execute_input":"2025-10-15T18:15:38.112754Z","iopub.status.idle":"2025-10-15T18:15:42.375639Z","shell.execute_reply.started":"2025-10-15T18:15:38.112728Z","shell.execute_reply":"2025-10-15T18:15:42.374374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_aggregated.head() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:15:45.349511Z","iopub.execute_input":"2025-10-15T18:15:45.349831Z","iopub.status.idle":"2025-10-15T18:15:45.397648Z","shell.execute_reply.started":"2025-10-15T18:15:45.349809Z","shell.execute_reply":"2025-10-15T18:15:45.396690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cust_id'ye gÃ¶re gruplayarak ortalamalarÄ± ve standart sapmalarÄ± alalÄ±m\nX_test_aggregated = X_test.groupby('cust_id').agg({\n    # Numeric deÄŸiÅŸkenlerin ortalamasÄ± ve standart sapmasÄ±\n    'mobile_eft_all_cnt': ['mean','std','min','max'],\n    'active_product_category_nbr': ['mean','std','min','max'],\n    'mobile_eft_all_amt': ['mean','min','std','max'],\n    'cc_transaction_all_amt': ['mean','min','std','max'],\n    'cc_transaction_all_cnt': ['mean','min','std','max'],\n    \n    # Demografik deÄŸiÅŸkenleri koru (first kullanarak ilk deÄŸeri al)\n    'gender': 'first',\n    'age': 'first',\n    'province': 'first',\n    'religion': 'first',\n    'work_type': 'first',\n    'work_sector': 'first',\n    'tenure': 'first',\n    'has_eft': 'first',\n    'has_cc_transaction': 'first',\n    'age_group': 'first',\n\n    # tenure related\n    'tenure_lifecycle':'first',\n    'transaction_intensity':'mean',\n    'customer_value_per_month':'mean',\n    'tenure_age_ratio':'mean',\n    'tenure_relative_to_age':'mean',\n    'tenure_risk_segment':'first',\n    #\n    'total_transaction_count':'mean',\n    'total_transaction_amount':'mean',\n    'has_both_transaction_types':'first',\n    'overall_avg_transaction_size':'mean',\n    'monthly_avg_transaction_count':'mean',\n    'monthly_avg_transaction_amount':'mean',\n    'transaction_frequency':'mean',\n    'product_usage_intensity':'mean',\n    'age_tenure_segment':'first',\n    'transaction_consistency_score':'mean',\n    #\n    'age_x_tenure':'mean',\n    'avg_transaction_x_product_count':'mean',\n    'tenure_x_monthly_transactions':'mean',\n    #\n    'recency_score':\"mean\",\n    'frequency_score':\"mean\",\n    'monetary_score':\"mean\",\n    'rfm_segment':\"first\",\n    'rfm_score':'mean',\n    #\n    'days_before_ref':'mean',\n    'days_since_previous_transaction':'mean',\n    'amt_last_30d':'mean',\n    'cnt_last_30d':'mean',\n    'amt_last_90d':'mean',\n    'cnt_last_90d':'mean'\n}).reset_index()\n\n# Column isimlerini dÃ¼zelt\nX_test_aggregated.columns = ['_'.join(col).strip() if col[1] != 'first' else col[0] for col in X_test_aggregated.columns]\nX_test_aggregated = X_test_aggregated.rename(columns={'cust_id_': 'cust_id'})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:15:54.006030Z","iopub.execute_input":"2025-10-15T18:15:54.007508Z","iopub.status.idle":"2025-10-15T18:15:55.987237Z","shell.execute_reply.started":"2025-10-15T18:15:54.007459Z","shell.execute_reply":"2025-10-15T18:15:55.986056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kategorik deÄŸiÅŸkenleri one-hot encoding yapalÄ±m\ncategorical_columns = ['gender', 'province', 'religion', 'work_type', 'work_sector', 'age_group',\n                       'tenure_lifecycle','tenure_risk_segment','age_tenure_segment','rfm_segment']\n\n# One-hot encoding uygula ve boolean deÄŸerleri integer'a Ã§evir\nX_train_encoded = pd.get_dummies(X_train_aggregated, columns=categorical_columns, drop_first=True)\n\n# Boolean kolonlarÄ± integer'a Ã§evir (True->1, False->0)\nbool_columns = X_train_encoded.select_dtypes(include=['bool']).columns\nX_train_encoded[bool_columns] = X_train_encoded[bool_columns].astype(int)\n\nX_train_encoded.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:16:04.778583Z","iopub.execute_input":"2025-10-15T18:16:04.778930Z","iopub.status.idle":"2025-10-15T18:16:05.049416Z","shell.execute_reply.started":"2025-10-15T18:16:04.778906Z","shell.execute_reply":"2025-10-15T18:16:05.048185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kategorik deÄŸiÅŸkenleri one-hot encoding yapalÄ±m\ncategorical_columns = ['gender', 'province', 'religion', 'work_type', 'work_sector', 'age_group',\n                       'tenure_lifecycle','tenure_risk_segment','age_tenure_segment','rfm_segment']\n\n# One-hot encoding uygula ve boolean deÄŸerleri integer'a Ã§evir\nX_test_encoded = pd.get_dummies(X_test_aggregated, columns=categorical_columns, drop_first=True)\n\n# Boolean kolonlarÄ± integer'a Ã§evir (True->1, False->0)\nbool_columns = X_test_encoded.select_dtypes(include=['bool']).columns\nX_test_encoded[bool_columns] = X_test_encoded[bool_columns].astype(int)\n\nX_test_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:16:07.014995Z","iopub.execute_input":"2025-10-15T18:16:07.015712Z","iopub.status.idle":"2025-10-15T18:16:07.145424Z","shell.execute_reply.started":"2025-10-15T18:16:07.015683Z","shell.execute_reply":"2025-10-15T18:16:07.144326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"model","metadata":{}},{"cell_type":"markdown","source":"imp","metadata":{}},{"cell_type":"code","source":"X_train_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:16:09.227247Z","iopub.execute_input":"2025-10-15T18:16:09.227583Z","iopub.status.idle":"2025-10-15T18:16:09.282822Z","shell.execute_reply.started":"2025-10-15T18:16:09.227560Z","shell.execute_reply":"2025-10-15T18:16:09.281601Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"MODEL","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport optuna\n\n# Feature ve target'Ä± ayÄ±rma\nX = X_train_encoded.drop(['cust_id', 'churn'], axis=1)\ny = X_train_encoded['churn']\n\n# Train-validation split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")\nprint(f\"Churn rate - Train: {y_train.mean():.4f}, Validation: {y_val.mean():.4f}\")\n\n# Optuna ile ING metriÄŸini optimize edecek ÅŸekilde hyperparameter tuning\ndef objective(trial):\n    params = {\n        'objective': 'binary',\n        'metric': 'auc',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n        'scale_pos_weight': len(y_train[y_train==0]) / len(y_train[y_train==1]),\n        'random_state': 42\n    }\n    \n    # 3-fold cross validation\n    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    ing_scores = []\n    \n    for train_idx, val_idx in skf.split(X_train, y_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n        \n        model = lgb.LGBMClassifier(**params)\n        model.fit(X_fold_train, y_fold_train)\n        \n        y_val_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n        ing_score = ing_hubs_datathon_metric(y_fold_val, y_val_pred_proba)\n        ing_scores.append(ing_score)\n    \n    return np.mean(ing_scores)\n\n# Optuna Ã§alÄ±ÅŸmasÄ±\nprint(\"Optuna tuning baÅŸlÄ±yor...\")\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100, show_progress_bar=True)\n\n# En iyi parametrelerle model eÄŸitimi\nbest_params = study.best_params\nprint(f\"Best ING Score: {study.best_value:.4f}\")\nprint(\"Best parameters:\", best_params)\n\n# Final modeli eÄŸitme\nfinal_model = lgb.LGBMClassifier(\n    **best_params,\n    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),\n    random_state=42,\n    verbose=1\n)\n\nfinal_model.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    eval_metric='auc',\n    callbacks=[lgb.early_stopping(50)]\n)\n\n# Validation setinde deÄŸerlendirme\ny_val_pred_proba = final_model.predict_proba(X_val)[:, 1]\nval_ing_score = ing_hubs_datathon_metric(y_val, y_val_pred_proba)\nval_auc = roc_auc_score(y_val, y_val_pred_proba)\n\nprint(f\"\\n=== VALIDATION SONUÃ‡LARI ===\")\nprint(f\"ING Score: {val_ing_score:.4f}\")\nprint(f\"AUC: {val_auc:.4f}\")\nprint(f\"Gini: {convert_auc_to_gini(val_auc):.4f}\")\nprint(f\"Recall@10%: {recall_at_k(y_val, y_val_pred_proba, k=0.1):.4f}\")\nprint(f\"Lift@10%: {lift_at_k(y_val, y_val_pred_proba, k=0.1):.4f}\")\n\n# Feature importance\nfeature_importance = pd.DataFrame({\n    'feature': X.columns,\n    'importance': final_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(f\"\\n=== TOP 10 FEATURE IMPORTANCE ===\")\nprint(feature_importance.head(10))\n\n\"\"\"\n# TÃ¼m eÄŸitim verisi ile final modeli tekrar eÄŸitme (opsiyonel)\nprint(\"\\nTÃ¼m eÄŸitim verisi ile final model eÄŸitiliyor...\")\nfinal_model_full = lgb.LGBMClassifier(\n    **best_params,\n    scale_pos_weight=len(y[y==0]) / len(y[y==1]),\n    random_state=42,\n    verbose=1\n)\n\nfinal_model_full.fit(X, y)\nprint(\"Final model eÄŸitimi tamamlandÄ±!\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:29:46.610931Z","iopub.execute_input":"2025-10-15T18:29:46.611346Z","iopub.status.idle":"2025-10-15T18:56:50.158716Z","shell.execute_reply.started":"2025-10-15T18:29:46.611321Z","shell.execute_reply":"2025-10-15T18:56:50.157376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nfeature_importance.head(82)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:25:12.948570Z","iopub.execute_input":"2025-10-15T18:25:12.948971Z","iopub.status.idle":"2025-10-15T18:25:12.964196Z","shell.execute_reply.started":"2025-10-15T18:25:12.948946Z","shell.execute_reply":"2025-10-15T18:25:12.963016Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:09:12.443467Z","iopub.execute_input":"2025-10-15T18:09:12.443885Z","iopub.status.idle":"2025-10-15T18:09:12.492459Z","shell.execute_reply.started":"2025-10-15T18:09:12.443857Z","shell.execute_reply":"2025-10-15T18:09:12.490819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# X ve y'yi tek bir DataFrame'te birleÅŸtir\ndf_corr = X_train_encoded.copy()\ndf_corr['churn'] = y_train\n\n# KorelasyonlarÄ± hesapla\ncorr_with_churn = df_corr.corr(numeric_only=True)['churn'].sort_values(ascending=False)\nprint(corr_with_churn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:25:19.087733Z","iopub.execute_input":"2025-10-15T18:25:19.088340Z","iopub.status.idle":"2025-10-15T18:25:24.132367Z","shell.execute_reply.started":"2025-10-15T18:25:19.088294Z","shell.execute_reply":"2025-10-15T18:25:24.130785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport optuna\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0 # Handle cases with only one class in y_true\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# LightGBM iÃ§in Ã¶zel metrik wrapper'Ä±\ndef lgbm_eval_metric(y_true, y_pred):\n    return 'ing_metric', ing_hubs_datathon_metric(y_true, y_pred), True\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df):\n    \"\"\"KapsamlÄ± Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    \n    # GÃœNCELLEME: ref_date ile aynÄ± aydaki verileri de dahil et\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    # Yeni temel Ã¶zellikler oluÅŸtur\n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['avg_cc_amt_per_txn'] = history['cc_transaction_all_amt'] / (history['cc_transaction_all_cnt'] + 1e-6)\n    history['avg_eft_amt_per_txn'] = history['mobile_eft_all_amt'] / (history['mobile_eft_all_cnt'] + 1e-6)\n    # HATA DÃœZELTMESÄ°: GÃ¼venilir ay farkÄ± hesaplamasÄ±\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    # 1. Zaman BazlÄ± Agregasyon Ã–zellikleri\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt', 'avg_cc_amt_per_txn', 'avg_eft_amt_per_txn',\n        'months_before_ref' # DÃœZELTME: 'months_before_ref' eklendi\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max', 'last', 'first', 'nunique']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    time_windows = [3, 6, 12]\n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n\n    for window in time_windows:\n        # pencere hesaplamalarÄ±nda 0. ay (ref_date ayÄ±) dahil edilmemeli\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    # 2. Trend Ã–zellikleri\n    print(\"  -> Trend Ã¶zellikleri oluÅŸturuluyor...\")\n    for col in cols_to_agg:\n        if col != 'months_before_ref': # 'months_before_ref' iÃ§in trend anlamsÄ±z\n            df[f'{col}_trend_3m_vs_12m'] = df[f'{col}_mean_last_3m'] / (df[f'{col}_mean_last_12m'] + 1e-6)\n            df[f'{col}_trend_6m_vs_12m'] = df[f'{col}_mean_last_6m'] / (df[f'{col}_mean_last_12m'] + 1e-6)\n\n    # 3. Gecikme (Lag) Ã–zellikleri\n    print(\"  -> Gecikme (Lag) Ã¶zellikleri oluÅŸturuluyor...\")\n    history_pivoted = history.pivot_table(index='cust_id', columns='months_before_ref', values=['total_transaction_amt', 'total_transaction_cnt'])\n    history_pivoted.columns = [f'{col[0]}_lag_{col[1]}' for col in history_pivoted.columns]\n    for lag in range(1, 4): # Son 3 ayÄ±n lag'lerini ekle\n        for col in ['total_transaction_amt', 'total_transaction_cnt']:\n            if f'{col}_lag_{lag}' in history_pivoted.columns:\n                 df = pd.merge(df, history_pivoted[[f'{col}_lag_{lag}']], on='cust_id', how='left')\n    \n    # 4. MÃ¼ÅŸteri Aktivite Ã–zellikleri\n    print(\"  -> MÃ¼ÅŸteri aktivite Ã¶zellikleri oluÅŸturuluyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index()\n    last_transaction.rename(columns={'date': 'last_transaction_date'}, inplace=True)\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index()\n    first_transaction.rename(columns={'date': 'first_transaction_date'}, inplace=True)\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n    df['customer_history_length_days'] = (df['last_transaction_date'] - df['first_transaction_date']).dt.days\n    # DÃœZELTME: 'min' metriÄŸi kullanÄ±larak mantÄ±k dÃ¼zeltildi\n    df['is_active_last_1m'] = (df['months_before_ref_min_all'] == 0).astype(int)\n\n\n    # Final dokunuÅŸlar\n    df = df.drop(columns=['last_transaction_date', 'first_transaction_date'], errors='ignore')\n    categorical_features = ['gender', 'province', 'religion', 'work_type', 'work_sector']\n    for col in categorical_features:\n        df[col] = df[col].astype('category')\n    \n    # Sonsuz deÄŸerleri NaN ile deÄŸiÅŸtir\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef train_and_predict(train_df, test_df, sample_submission_df, n_trials_optuna=5):\n    \"\"\"Optuna ile modeli optimize eder, eÄŸitir ve tahminleri oluÅŸturur.\"\"\"\n    print(\"Optuna ile model optimizasyonu ve eÄŸitimi baÅŸlÄ±yor.\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    X_train, y_train = train_df[features], train_df[target]\n    X_test = test_df[features]\n    \n    # SÄ±nÄ±f dengesizliÄŸi iÃ§in scale_pos_weight hesapla\n    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n    print(f\"SÄ±nÄ±f dengesizliÄŸi oranÄ± iÃ§in scale_pos_weight hesaplandÄ±: {scale_pos_weight:.2f}\")\n\n    def objective(trial):\n        params = {\n            'objective': 'binary',\n            'metric': 'none', # Ã–zel metrik kullanÄ±ldÄ±ÄŸÄ± iÃ§in 'none'\n            'boosting_type': 'gbdt',\n            'n_estimators': 1000,\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n            'max_depth': trial.suggest_int('max_depth', 5, 12),\n            'seed': 42,\n            'n_jobs': -1,\n            'verbose': -1,\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n            'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 1.0),\n            'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 1.0),\n            'scale_pos_weight': scale_pos_weight\n        }\n        \n        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        scores = []\n        for train_idx, val_idx in skf.split(X_train, y_train):\n            X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n            X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n            \n            model = lgb.LGBMClassifier(**params)\n            model.fit(X_train_fold, y_train_fold, \n                      eval_set=[(X_val_fold, y_val_fold)], \n                      eval_metric=lgbm_eval_metric,\n                      callbacks=[lgb.early_stopping(50, verbose=False)])\n            \n            preds = model.predict_proba(X_val_fold)[:, 1]\n            scores.append(ing_hubs_datathon_metric(y_val_fold, preds))\n        \n        return np.mean(scores)\n\n    print(f\"  -> Optuna optimizasyon Ã§alÄ±ÅŸmasÄ± baÅŸlatÄ±lÄ±yor ({n_trials_optuna} deneme)...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=n_trials_optuna)\n    \n    best_params = study.best_params\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu:\", best_params)\n    \n    # Final modeli eÄŸit ve tahmin yap\n    print(\"En iyi parametrelerle final modeli eÄŸitiliyor...\")\n    final_params = {**best_params, 'n_estimators': 2000, 'scale_pos_weight': scale_pos_weight}\n    \n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    test_preds = np.zeros(len(X_test))\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n        print(f\"  -> Fold {fold+1} eÄŸitiliyor...\")\n        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n        \n        model = lgb.LGBMClassifier(**final_params)\n        model.fit(X_train_fold, y_train_fold, \n                  eval_set=[(X_val_fold, y_val_fold)], \n                  eval_metric=lgbm_eval_metric,\n                  callbacks=[lgb.early_stopping(100, verbose=False)])\n        \n        test_preds += model.predict_proba(X_test)[:, 1] / skf.n_splits\n        \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = test_preds\n    submission_df.to_csv('submission_optuna.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_optuna.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured = feature_engineering(train_ref, customers, customer_history)\n    test_featured = feature_engineering(test_ref, customers, customer_history)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = train_and_predict(train_featured, test_featured, sample_submission, n_trials_optuna=5)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:31:05.827742Z","iopub.execute_input":"2025-10-15T21:31:05.828106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"sa\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:20:28.900398Z","iopub.execute_input":"2025-10-15T21:20:28.900735Z","iopub.status.idle":"2025-10-15T21:20:28.906763Z","shell.execute_reply.started":"2025-10-15T21:20:28.900709Z","shell.execute_reply":"2025-10-15T21:20:28.905439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    \n    # GÃœNCELLEME: work_sector iÃ§in yeni doldurma mantÄ±ÄŸÄ±\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    \n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [3, 6, 9, 12]\n    \n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> Zaman penceresi etkileÅŸim Ã¶zellikleri oluÅŸturuluyor...\")\n    windows = [3, 6, 9, 12]\n    for i in range(len(windows)):\n        for j in range(i + 1, len(windows)):\n            win1 = windows[i]\n            win2 = windows[j]\n            for col in ['total_transaction_amt', 'total_transaction_cnt']:\n                for stat in ['mean', 'sum']:\n                    df[f'ratio_{col}_{stat}_{win1}m_vs_{win2}m'] = df[f'{col}_{stat}_last_{win1}m'] / (df[f'{col}_{stat}_last_{win2}m'] + 1e-6)\n                    df[f'diff_{col}_{stat}_{win1}m_vs_{win2}m'] = df[f'{col}_{stat}_last_{win1}m'] - df[f'{col}_{stat}_last_{win2}m']\n    \n    print(\"  -> RFM ve davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    \n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n    df['eft_to_cc_amt_ratio_all'] = df['mobile_eft_all_amt_sum_all'] / (df['cc_transaction_all_amt_sum_all'] + 1e-6)\n    df['eft_to_cc_cnt_ratio_all'] = df['mobile_eft_all_cnt_sum_all'] / (df['cc_transaction_all_cnt_sum_all'] + 1e-6)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n\n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    # Final dokunuÅŸlar: Ã–nce kategorikleri iÅŸle, sonra numerikleri doldur\n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        # HATA DÃœZELTMESÄ°: Kategori zaten varsa, yeni kategori eklemeden Ã¶nce kontrol et\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef train_catboost_model(train_df, test_df, sample_submission_df):\n    \"\"\"Nadir kategori birleÅŸtirme, korelasyon temizliÄŸi ve K-Fold iÃ§i Target Encoding ile CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 25].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.97)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    model_params = {\n        'iterations': 6000,\n        'depth': 4,\n        'learning_rate': 0.05,\n        'max_bin': 64,\n        'allow_writing_files': False,\n        'random_state': 0\n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=0)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        print(\"    -> Target encoding uygulanÄ±yor...\")\n        global_mean_fold = y_train_fold.mean()\n\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            \n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            \n            X_train_fold[col] = X_train_fold[col].map(smooth_means)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=40,\n                  verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        \n        del X_train_fold, y_train_fold, X_val_fold\n        gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF (Out-of-Fold) Skoru: {final_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = test_preds\n    submission_df.to_csv('submission_catboost_target_encoded.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_target_encoded.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = train_catboost_model(train_featured, test_featured, sample_submission)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T18:47:38.357886Z","iopub.execute_input":"2025-10-17T18:47:38.358249Z","iopub.status.idle":"2025-10-17T18:50:41.185235Z","shell.execute_reply.started":"2025-10-17T18:47:38.358227Z","shell.execute_reply":"2025-10-17T18:50:41.184066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nimport optuna\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [1, 2, 3, 6, 9, 12, 15, 18]\n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> Zaman penceresi etkileÅŸim Ã¶zellikleri oluÅŸturuluyor...\")\n    windows = [1, 2, 3, 6, 9, 12, 15, 18]\n    for i in range(len(windows)):\n        for j in range(i + 1, len(windows)):\n            win1 = windows[i]; win2 = windows[j]\n            for col in ['total_transaction_amt', 'total_transaction_cnt', 'active_product_category_nbr']:\n                for stat in ['mean', 'sum']:\n                    df[f'ratio_{col}_{stat}_{win1}m_vs_{win2}m'] = df[f'{col}_{stat}_last_{win1}m'] / (df[f'{col}_{stat}_last_{win2}m'] + 1e-6)\n                    df[f'diff_{col}_{stat}_{win1}m_vs_{win2}m'] = df[f'{col}_{stat}_last_{win1}m'] - df[f'{col}_{stat}_last_{win2}m']\n    \n    print(\"  -> RFM ve davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n    df['eft_amt_per_txn_all'] = df['mobile_eft_all_amt_sum_all'] / (df['mobile_eft_all_cnt_sum_all'] + 1e-6)\n    df['cc_amt_per_txn_all'] = df['cc_transaction_all_amt_sum_all'] / (df['cc_transaction_all_cnt_sum_all'] + 1e-6)\n    df['active_prod_per_active_month'] = df['active_product_category_nbr_sum_all'] / (df['date_nunique_all'] + 1e-6)\n    df['last_month_activity_share_cnt'] = df['total_transaction_cnt_sum_last_1m'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n    \n    history['days_between_transactions'] = history.groupby('cust_id')['date'].diff().dt.days\n    days_between_stats = history.groupby('cust_id')['days_between_transactions'].agg(['mean', 'std']).rename(columns={'mean': 'days_between_txn_mean', 'std': 'days_between_txn_std'})\n    df = pd.merge(df, days_between_stats, on='cust_id', how='left')\n    df['amt_coeff_variation'] = df['total_transaction_amt_std_all'] / (df['total_transaction_amt_mean_all'] + 1e-6)\n    df['is_spending_decreasing_sharply'] = (df['total_transaction_amt_sum_last_1m'] < df['total_transaction_amt_mean_last_6m'] * 0.5).astype(int)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count', 'amt_coeff_variation']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n    df['health_score_x_tenure'] = df['customer_health_score'] * df['tenure']\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n\n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n    df['religion_x_work_sector'] = df['religion'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_loyalty_tier'] = df['province'].astype(str) + '_' + df['loyalty_tier'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef optimize_and_train_catboost(train_df, test_df, sample_submission_df, n_trials_optuna=20):\n    \"\"\"Optuna ile optimize edilmiÅŸ CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 30].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.94)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    # Optuna Objective Function\n    def objective(trial):\n        params = {\n            'iterations': 6000,\n            'depth': trial.suggest_int('depth', 5, 9),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n            'max_bin': trial.suggest_int('max_bin', 32, 128),\n            'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n            'allow_writing_files': False,\n            'random_state': 0\n        }\n        \n        cv_opt = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n        scores = []\n        for train_idx, val_idx in cv_opt.split(train_df, train_df[target]):\n            X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n            X_val_fold = train_df.iloc[val_idx].copy()\n            \n            global_mean_fold = y_train_fold.mean()\n            alpha = 5\n            for col in cat_cols:\n                counts = X_train_fold[col].value_counts()\n                means = y_train_fold.groupby(X_train_fold[col]).mean()\n                smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n                \n                X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n                X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n            \n            model = CatBoostClassifier(**params)\n            model.fit(X_train_fold[features], y_train_fold,\n                      eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                      early_stopping_rounds=40, verbose=0)\n            \n            preds = model.predict_proba(X_val_fold[features])[:, 1]\n            scores.append(ing_hubs_datathon_metric(train_df[target].iloc[val_idx], preds))\n        return np.mean(scores)\n\n    print(f\"\\nOptuna ile optimizasyon baÅŸlÄ±yor ({n_trials_optuna} deneme)...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=n_trials_optuna)\n    best_params = study.best_params\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu:\", best_params)\n\n    # Final Model EÄŸitimi\n    final_model_params = {\n        'iterations': 6000,\n        **best_params \n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=1)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).astype(float).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        global_mean_fold = y_train_fold.mean()\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            \n            X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**final_model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=40,\n                  verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        \n        del X_train_fold, y_train_fold, X_val_fold\n        gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF (Out-of-Fold) Skoru: {final_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = test_preds\n    submission_df.to_csv('submission_catboost_target_encoded.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_target_encoded.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = optimize_and_train_catboost(train_featured, test_featured, sample_submission, n_trials_optuna=50)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T15:15:56.452925Z","iopub.execute_input":"2025-10-18T15:15:56.453336Z","iopub.status.idle":"2025-10-18T17:23:41.472093Z","shell.execute_reply.started":"2025-10-18T15:15:56.453309Z","shell.execute_reply":"2025-10-18T17:23:41.470997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.calibration import IsotonicRegression\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ \"ultimate\" Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [1, 3, 6, 9, 12, 15, 18, 24]\n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\")\n    for window in [3, 6, 12]:\n        if f'total_transaction_amt_sum_last_{window*2}m' in df.columns:\n            df[f'transaction_growth_{window}m'] = (df[f'total_transaction_amt_sum_last_{window}m'] - df[f'total_transaction_amt_sum_last_{window*2}m']) / (df[f'total_transaction_amt_sum_last_{window*2}m'] + 1e-6)\n\n    df['ref_month'] = df['ref_date'].dt.month\n    df['ref_quarter'] = df['ref_date'].dt.quarter\n    df['is_year_end'] = df['ref_month'].isin([12, 1]).astype(int)\n\n    for col in ['total_transaction_amt', 'total_transaction_cnt']:\n        for window in [3, 6]:\n            mean_col = f'{col}_mean_last_{window}m'\n            std_col = f'{col}_std_last_{window}m'\n            current_col = f'{col}_sum_last_1m'\n            if mean_col in df.columns and std_col in df.columns and current_col in df.columns:\n                df[f'{col}_zscore_1m_vs_{window}m'] = (df[current_col] - df[mean_col]) / (df[std_col] + 1e-6)\n    \n    print(\"  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n    \n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef train_catboost_model(train_df, test_df, sample_submission_df):\n    \"\"\"Nadir kategori birleÅŸtirme, korelasyon temizliÄŸi, Target Encoding ve Kalibrasyon ile CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 25].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.97)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    model_params = {\n        'iterations': 6000, 'depth': 4, 'learning_rate': 0.05,\n        'max_bin': 64, 'allow_writing_files': False, 'random_state': 0\n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=0)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).astype(float).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        print(\"    -> Target encoding uygulanÄ±yor...\")\n        global_mean_fold = y_train_fold.mean()\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=40, verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        \n        del X_train_fold, y_train_fold, X_val_fold; gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF Skoru (Kalibrasyon Ã–ncesi): {final_oof_score:.5f}\")\n    \n    print(\"  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\")\n    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n    iso_reg.fit(oof_preds, train_df[target])\n    calibrated_test_preds = iso_reg.transform(test_preds)\n\n    calibrated_oof_score = ing_hubs_datathon_metric(train_df[target], iso_reg.transform(oof_preds))\n    print(f\"Final OOF Skoru (Kalibrasyon SonrasÄ±): {calibrated_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = calibrated_test_preds\n    submission_df.to_csv('submission_catboost_calibrated.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref; gc.collect()\n\n    submission = train_catboost_model(train_featured, test_featured, sample_submission)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T07:27:48.124654Z","iopub.execute_input":"2025-10-20T07:27:48.125015Z","iopub.status.idle":"2025-10-20T07:31:17.643383Z","shell.execute_reply.started":"2025-10-20T07:27:48.124987Z","shell.execute_reply":"2025-10-20T07:31:17.642349Z"}},"outputs":[{"name":"stdout","text":"Veri setleri yÃ¼kleniyor...\nVeri setleri baÅŸarÄ±yla yÃ¼klendi.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 133287 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 352 Ã¶zellik oluÅŸturuldu.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 43006 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 351 Ã¶zellik oluÅŸturuldu.\nNihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\n  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\n  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\n    -> 184 Ã¶zellik kaldÄ±rÄ±ldÄ±.\n\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\n===== Fold 1 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6562318\ttest: 0.6562752\tbest: 0.6562752 (0)\ttotal: 38.9ms\tremaining: 3m 53s\n500:\tlearn: 0.3603971\ttest: 0.3667864\tbest: 0.3667656 (478)\ttotal: 17.3s\tremaining: 3m 10s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3660934913\nbestIteration = 754\n\nShrink model to first 755 iterations.\n===== Fold 2 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6562223\ttest: 0.6564524\tbest: 0.6564524 (0)\ttotal: 41.3ms\tremaining: 4m 8s\n500:\tlearn: 0.3604277\ttest: 0.3675489\tbest: 0.3675424 (498)\ttotal: 16.1s\tremaining: 2m 57s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3672479549\nbestIteration = 727\n\nShrink model to first 728 iterations.\n===== Fold 3 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6561878\ttest: 0.6561828\tbest: 0.6561828 (0)\ttotal: 40.9ms\tremaining: 4m 5s\n500:\tlearn: 0.3597463\ttest: 0.3702876\tbest: 0.3702698 (468)\ttotal: 16.9s\tremaining: 3m 5s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3702698095\nbestIteration = 468\n\nShrink model to first 469 iterations.\n===== Fold 4 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6561930\ttest: 0.6562984\tbest: 0.6562984 (0)\ttotal: 42.7ms\tremaining: 4m 16s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3704743163\nbestIteration = 412\n\nShrink model to first 413 iterations.\n===== Fold 5 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6561158\ttest: 0.6563600\tbest: 0.6563600 (0)\ttotal: 39.2ms\tremaining: 3m 55s\n500:\tlearn: 0.3599627\ttest: 0.3695886\tbest: 0.3695791 (496)\ttotal: 16.1s\tremaining: 2m 56s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.369372002\nbestIteration = 636\n\nShrink model to first 637 iterations.\n===== Fold 6 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6563019\ttest: 0.6562115\tbest: 0.6562115 (0)\ttotal: 39.4ms\tremaining: 3m 56s\n500:\tlearn: 0.3609346\ttest: 0.3650020\tbest: 0.3649651 (468)\ttotal: 16s\tremaining: 2m 55s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3649651079\nbestIteration = 468\n\nShrink model to first 469 iterations.\n===== Fold 7 =====\n    -> Target encoding uygulanÄ±yor...\n0:\tlearn: 0.6562474\ttest: 0.6561502\tbest: 0.6561502 (0)\ttotal: 40.3ms\tremaining: 4m 1s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3688162252\nbestIteration = 293\n\nShrink model to first 294 iterations.\n\n==============================================\nFinal OOF Skoru (Kalibrasyon Ã–ncesi): 1.18099\n  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\nFinal OOF Skoru (Kalibrasyon SonrasÄ±): 1.18329\n==============================================\n\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\n\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\n   cust_id     churn\n0        1  0.132321\n1        2  0.118160\n2        9  0.242960\n3       15  0.240785\n4       19  0.045282\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"early stopping -l2 leaf ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.calibration import IsotonicRegression\nimport optuna\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ \"ultimate\" Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max','median']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [1, 3, 6, 9, 12, 15, 18, 24, 27]\n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\")\n    for window in [1, 3, 6, 12]:\n        if f'total_transaction_amt_sum_last_{window*2}m' in df.columns:\n            df[f'transaction_growth_{window}m'] = (df[f'total_transaction_amt_sum_last_{window}m'] - df[f'total_transaction_amt_sum_last_{window*2}m']) / (df[f'total_transaction_amt_sum_last_{window*2}m'] + 1e-6)\n\n    df['ref_month'] = df['ref_date'].dt.month\n    df['ref_quarter'] = df['ref_date'].dt.quarter\n    df['is_year_end'] = df['ref_month'].isin([12, 1]).astype(int)\n\n    for col in ['total_transaction_amt', 'total_transaction_cnt']:\n        for window in [1, 3, 6, 12]:\n            mean_col = f'{col}_mean_last_{window}m'\n            std_col = f'{col}_std_last_{window}m'\n            current_col = f'{col}_sum_last_1m'\n            if mean_col in df.columns and std_col in df.columns and current_col in df.columns:\n                df[f'{col}_zscore_1m_vs_{window}m'] = (df[current_col] - df[mean_col]) / (df[std_col] + 1e-6)\n    \n    print(\"  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n    \n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef optimize_and_train_catboost(train_df, test_df, sample_submission_df, n_trials_optuna=50):\n    \"\"\"Optuna ile optimize edilmiÅŸ CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 25].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.96)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    # Optuna Objective Function\n    def objective(trial):\n        params = {\n            'iterations': 6000,\n            'depth': trial.suggest_int('depth', 5, 9),\n            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10), \n            'max_bin': trial.suggest_int('max_bin', 32, 128),\n            'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n            'allow_writing_files': False,\n            'random_state': 0,\n            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 1.0)\n        }\n        \n        cv_opt = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n        scores = []\n        for train_idx, val_idx in cv_opt.split(train_df, train_df[target]):\n            X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n            X_val_fold = train_df.iloc[val_idx].copy()\n            \n            global_mean_fold = y_train_fold.mean()\n            alpha = 5\n            for col in cat_cols:\n                counts = X_train_fold[col].value_counts()\n                means = y_train_fold.groupby(X_train_fold[col]).mean()\n                smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n                \n                X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n                X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n            \n            model = CatBoostClassifier(**params)\n            model.fit(X_train_fold[features], y_train_fold,\n                      eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                      early_stopping_rounds=40, verbose=0) \n            \n            preds = model.predict_proba(X_val_fold[features])[:, 1]\n            scores.append(ing_hubs_datathon_metric(train_df[target].iloc[val_idx], preds))\n        return np.mean(scores)\n\n    print(f\"\\nOptuna ile optimizasyon baÅŸlÄ±yor ({n_trials_optuna} deneme)...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=n_trials_optuna)\n    best_params = study.best_params\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu:\", best_params)\n\n    # Final Model EÄŸitimi\n    final_model_params = {\n        'iterations': 6000,\n        **best_params \n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=1)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).astype(float).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        global_mean_fold = y_train_fold.mean()\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            \n            X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**final_model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=50,\n                  verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        \n        del X_train_fold, y_train_fold, X_val_fold\n        gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF Skoru (Kalibrasyon Ã–ncesi): {final_oof_score:.5f}\")\n    \n    print(\"  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\")\n    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n    iso_reg.fit(oof_preds, train_df[target])\n    calibrated_test_preds = iso_reg.transform(test_preds)\n\n    calibrated_oof_score = ing_hubs_datathon_metric(train_df[target], iso_reg.transform(oof_preds))\n    print(f\"Final OOF Skoru (Kalibrasyon SonrasÄ±): {calibrated_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = calibrated_test_preds\n    submission_df.to_csv('submission_catboost_calibrated.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = optimize_and_train_catboost(train_featured, test_featured, sample_submission, n_trials_optuna=40)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T17:17:35.822303Z","iopub.execute_input":"2025-10-21T17:17:35.822973Z","execution_failed":"2025-10-21T18:19:59.712Z"}},"outputs":[{"name":"stdout","text":"Veri setleri yÃ¼kleniyor...\nVeri setleri baÅŸarÄ±yla yÃ¼klendi.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 133287 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 459 Ã¶zellik oluÅŸturuldu.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 43006 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 458 Ã¶zellik oluÅŸturuldu.\nNihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\n  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\n  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-10-21 17:19:24,789] A new study created in memory with name: no-name-7054fbc7-f903-49c3-b2cc-d886f7d3bb2f\n","output_type":"stream"},{"name":"stdout","text":"    -> 325 Ã¶zellik kaldÄ±rÄ±ldÄ±.\n\nOptuna ile optimizasyon baÅŸlÄ±yor (40 deneme)...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-10-21 17:21:00,177] Trial 0 finished with value: 1.1739578755045594 and parameters: {'depth': 7, 'learning_rate': 0.03010509994820644, 'l2_leaf_reg': 7.222451472390871, 'max_bin': 108, 'random_strength': 7.301284568416977, 'bagging_temperature': 0.5107959782183001}. Best is trial 0 with value: 1.1739578755045594.\n[I 2025-10-21 17:23:14,735] Trial 1 finished with value: 1.1713661559512059 and parameters: {'depth': 8, 'learning_rate': 0.018847326855827854, 'l2_leaf_reg': 1.9844623067482021, 'max_bin': 66, 'random_strength': 3.8707121869929653, 'bagging_temperature': 0.034772021541371635}. Best is trial 0 with value: 1.1739578755045594.\n[I 2025-10-21 17:24:52,203] Trial 2 finished with value: 1.1797024397687268 and parameters: {'depth': 8, 'learning_rate': 0.02883133607454098, 'l2_leaf_reg': 2.8600185207938806, 'max_bin': 117, 'random_strength': 4.894502129571836, 'bagging_temperature': 0.635727421097438}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:25:47,576] Trial 3 finished with value: 1.1750245780934707 and parameters: {'depth': 5, 'learning_rate': 0.042505269503463075, 'l2_leaf_reg': 4.533601858183486, 'max_bin': 124, 'random_strength': 3.1753428356873226, 'bagging_temperature': 0.43734139681904155}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:30:06,873] Trial 4 finished with value: 1.1784320104877681 and parameters: {'depth': 9, 'learning_rate': 0.013745848825795708, 'l2_leaf_reg': 6.689644048834927, 'max_bin': 103, 'random_strength': 6.347390207823788, 'bagging_temperature': 0.8316258054136182}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:31:13,647] Trial 5 finished with value: 1.1670828097843946 and parameters: {'depth': 8, 'learning_rate': 0.03629426759823825, 'l2_leaf_reg': 4.026018135044907, 'max_bin': 96, 'random_strength': 2.437898643120163, 'bagging_temperature': 0.6359661200203578}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:32:10,740] Trial 6 finished with value: 1.1683532392484288 and parameters: {'depth': 5, 'learning_rate': 0.045175840916905394, 'l2_leaf_reg': 5.237003498102126, 'max_bin': 64, 'random_strength': 8.647941303019458, 'bagging_temperature': 0.7575051597778965}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:40:20,986] Trial 7 finished with value: 1.175079696668446 and parameters: {'depth': 5, 'learning_rate': 0.00312285582048672, 'l2_leaf_reg': 4.682039938631429, 'max_bin': 114, 'random_strength': 3.433470713896323, 'bagging_temperature': 0.8702483235862051}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:46:08,310] Trial 8 finished with value: 1.1713230285832894 and parameters: {'depth': 9, 'learning_rate': 0.007479681191970771, 'l2_leaf_reg': 1.6528131446254022, 'max_bin': 36, 'random_strength': 9.689807820976181, 'bagging_temperature': 0.9393750056163608}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:48:42,408] Trial 9 finished with value: 1.1744488592491784 and parameters: {'depth': 6, 'learning_rate': 0.013538703634734483, 'l2_leaf_reg': 4.212165840493172, 'max_bin': 32, 'random_strength': 8.750389260773822, 'bagging_temperature': 0.8903023725892525}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:50:14,319] Trial 10 finished with value: 1.1739437285322207 and parameters: {'depth': 7, 'learning_rate': 0.02727511585297526, 'l2_leaf_reg': 9.840542517362035, 'max_bin': 84, 'random_strength': 5.139215095857385, 'bagging_temperature': 0.272208903041741}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:53:21,836] Trial 11 finished with value: 1.1752246708325933 and parameters: {'depth': 9, 'learning_rate': 0.020638294209748977, 'l2_leaf_reg': 7.398523981774488, 'max_bin': 127, 'random_strength': 6.340761343847952, 'bagging_temperature': 0.6612483134085805}. Best is trial 2 with value: 1.1797024397687268.\n[I 2025-10-21 17:56:28,140] Trial 12 finished with value: 1.179886585876157 and parameters: {'depth': 8, 'learning_rate': 0.011812095129315452, 'l2_leaf_reg': 6.998036123611133, 'max_bin': 98, 'random_strength': 1.0030267315891628, 'bagging_temperature': 0.7383006417475471}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 17:57:48,987] Trial 13 finished with value: 1.1735945365951965 and parameters: {'depth': 8, 'learning_rate': 0.03256424586003458, 'l2_leaf_reg': 2.870416298823018, 'max_bin': 91, 'random_strength': 4.474242002919347, 'bagging_temperature': 0.4908599506963819}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 17:59:32,595] Trial 14 finished with value: 1.1757453645333875 and parameters: {'depth': 8, 'learning_rate': 0.021574924988721125, 'l2_leaf_reg': 8.695117403968531, 'max_bin': 75, 'random_strength': 1.4354865898482814, 'bagging_temperature': 0.6317776503407667}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 18:00:28,935] Trial 15 finished with value: 1.1736543836312487 and parameters: {'depth': 7, 'learning_rate': 0.03882438934864624, 'l2_leaf_reg': 6.218295719462923, 'max_bin': 118, 'random_strength': 1.3223398925007825, 'bagging_temperature': 0.29925051830002797}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 18:03:24,025] Trial 16 finished with value: 1.1761120174585968 and parameters: {'depth': 6, 'learning_rate': 0.012443113112004129, 'l2_leaf_reg': 3.2853822414351384, 'max_bin': 102, 'random_strength': 2.4238781578183537, 'bagging_temperature': 0.999649555712417}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 18:18:16,255] Trial 17 finished with value: 1.1674579492295487 and parameters: {'depth': 8, 'learning_rate': 0.0014576061285319665, 'l2_leaf_reg': 1.050396548581821, 'max_bin': 86, 'random_strength': 5.832963472820077, 'bagging_temperature': 0.7401794803168222}. Best is trial 12 with value: 1.179886585876157.\n[I 2025-10-21 18:19:31,079] Trial 18 finished with value: 1.1773514009092774 and parameters: {'depth': 6, 'learning_rate': 0.024537525233948792, 'l2_leaf_reg': 8.227912321199998, 'max_bin': 48, 'random_strength': 1.0235924680583466, 'bagging_temperature': 0.3706615169534909}. Best is trial 12 with value: 1.179886585876157.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.calibration import IsotonicRegression\nimport optuna\nimport warnings\nimport gc\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ \"ultimate\" Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max','median']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [1, 3, 6, 9, 12, 15, 18, 24]\n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\")\n    for window in [3, 6, 12]:\n        if f'total_transaction_amt_sum_last_{window*2}m' in df.columns:\n            df[f'transaction_growth_{window}m'] = (df[f'total_transaction_amt_sum_last_{window}m'] - df[f'total_transaction_amt_sum_last_{window*2}m']) / (df[f'total_transaction_amt_sum_last_{window*2}m'] + 1e-6)\n\n    df['ref_month'] = df['ref_date'].dt.month\n    df['ref_quarter'] = df['ref_date'].dt.quarter\n    df['is_year_end'] = df['ref_month'].isin([12, 1]).astype(int)\n\n    for col in ['total_transaction_amt', 'total_transaction_cnt']:\n        for window in [3, 6]:\n            mean_col = f'{col}_mean_last_{window}m'\n            std_col = f'{col}_std_last_{window}m'\n            current_col = f'{col}_sum_last_1m'\n            if mean_col in df.columns and std_col in df.columns and current_col in df.columns:\n                df[f'{col}_zscore_1m_vs_{window}m'] = (df[current_col] - df[mean_col]) / (df[std_col] + 1e-6)\n    \n    print(\"  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n    \n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef optimize_and_train_catboost(train_df, test_df, sample_submission_df, n_trials_optuna=50):\n    \"\"\"Optuna ile optimize edilmiÅŸ CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 25].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.96)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    # Optuna Objective Function\n    def objective(trial):\n        params = {\n            'iterations': 6000,\n            'depth': trial.suggest_int('depth', 5, 9),\n            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n            'max_bin': trial.suggest_int('max_bin', 32, 128),\n            'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n            'allow_writing_files': False,\n            'random_state': 0,\n            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 1.0)\n        }\n        \n        cv_opt = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n        scores = []\n        for train_idx, val_idx in cv_opt.split(train_df, train_df[target]):\n            X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n            X_val_fold = train_df.iloc[val_idx].copy()\n            \n            global_mean_fold = y_train_fold.mean()\n            alpha = 5\n            for col in cat_cols:\n                counts = X_train_fold[col].value_counts()\n                means = y_train_fold.groupby(X_train_fold[col]).mean()\n                smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n                \n                X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n                X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n            \n            model = CatBoostClassifier(**params)\n            model.fit(X_train_fold[features], y_train_fold,\n                      eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                      early_stopping_rounds=100, verbose=0)\n            \n            preds = model.predict_proba(X_val_fold[features])[:, 1]\n            scores.append(ing_hubs_datathon_metric(train_df[target].iloc[val_idx], preds))\n        return np.mean(scores)\n\n    print(f\"\\nOptuna ile optimizasyon baÅŸlÄ±yor ({n_trials_optuna} deneme)...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=n_trials_optuna)\n    best_params = study.best_params\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu:\", best_params)\n\n    # Final Model EÄŸitimi\n    final_model_params = {\n        'iterations': 6000,\n        **best_params \n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=1)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).astype(float).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        global_mean_fold = y_train_fold.mean()\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            \n            X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**final_model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=40,\n                  verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        \n        del X_train_fold, y_train_fold, X_val_fold\n        gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF Skoru (Kalibrasyon Ã–ncesi): {final_oof_score:.5f}\")\n    \n    print(\"  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\")\n    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n    iso_reg.fit(oof_preds, train_df[target])\n    calibrated_test_preds = iso_reg.transform(test_preds)\n\n    calibrated_oof_score = ing_hubs_datathon_metric(train_df[target], iso_reg.transform(oof_preds))\n    print(f\"Final OOF Skoru (Kalibrasyon SonrasÄ±): {calibrated_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = calibrated_test_preds\n    submission_df.to_csv('submission_catboost_calibrated.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = optimize_and_train_catboost(train_featured, test_featured, sample_submission, n_trials_optuna=30)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T19:00:41.871096Z","iopub.execute_input":"2025-10-21T19:00:41.871402Z","iopub.status.idle":"2025-10-21T19:00:57.265047Z","shell.execute_reply.started":"2025-10-21T19:00:41.871377Z","shell.execute_reply":"2025-10-21T19:00:57.262837Z"}},"outputs":[{"name":"stdout","text":"Veri setleri yÃ¼kleniyor...\nVeri setleri baÅŸarÄ±yla yÃ¼klendi.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 133287 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/294860698.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mcustomer_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mtrain_featured\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_health\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mtest_featured\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmeans_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_health\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_health\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/294860698.py\u001b[0m in \u001b[0;36mfeature_engineering\u001b[0;34m(ref_df, customers_df, history_df, kmeans_model, scaler_health)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtime_windows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mperiod_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'months_before_ref'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mgrouped_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cust_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mgrouped_period\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'_last_{window}m'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_period\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cust_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0;31m# GH #52849\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_or_apply_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     def compute_dict_like(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         ):\n\u001b[0;32m-> 1608\u001b[0;31m             result_index, result_data = self.compute_dict_like(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mcompute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m    497\u001b[0m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             results = [\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_multiple_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrelabeling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# columns is not narrowed by mypy from relabeling flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(self, numeric_only)\u001b[0m\n\u001b[1;32m   2530\u001b[0m         \u001b[0mFreq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \"\"\"\n\u001b[0;32m-> 2532\u001b[0;31m         result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   2533\u001b[0m             \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m             \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"idxmin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"idxmax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0marray_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                 result = self._grouper._cython_operation(\n\u001b[0m\u001b[1;32m   1974\u001b[0m                     \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         return cy_op.cython_operation(\n\u001b[0m\u001b[1;32m    832\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mcython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         return self._cython_op_ndim_compat(\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mresult_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             res = self._call_cython_op(\n\u001b[0m\u001b[1;32m    330\u001b[0m                 \u001b[0mvalues2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sem\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_datetimelike\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 func(\n\u001b[0m\u001b[1;32m    433\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                     \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.calibration import IsotonicRegression\nimport optuna\nimport warnings\nimport gc\nimport matplotlib.pyplot as plt\n\n# UyarÄ±larÄ± bastÄ±r\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Optuna loglamasÄ±nÄ± aÃ§arak her adÄ±mÄ± izleyelim\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\n# =============================================================================\n# YARIÅžMA METRÄ°ÄžÄ° AYARLARI\n# =============================================================================\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n    return float(tp_at_k / P) if P > 0 else 0.0\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\ndef convert_auc_to_gini(auc):\n    return 2 * auc - 1\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    score_weights = {\"gini\": 0.4, \"recall_at_10perc\": 0.3, \"lift_at_10perc\": 0.3}\n    baseline_scores = {\"roc_auc\": 0.6925726757936908, \"recall_at_10perc\": 0.18469015795868773, \"lift_at_10perc\": 1.847159286784029}\n    \n    try:\n        roc_auc = roc_auc_score(y_true, y_prob)\n    except ValueError:\n        return 0.0\n        \n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\"roc_auc\": roc_auc, \"recall_at_10perc\": recall_at_10perc, \"lift_at_10perc\": lift_at_10perc}\n    \n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n    \n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"] if baseline_scores[\"gini\"] != 0 else 0\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"] if baseline_scores[\"recall_at_10perc\"] != 0 else 0\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"] if baseline_scores[\"lift_at_10perc\"] != 0 else 0\n    \n    final_score = (final_gini_score * score_weights[\"gini\"] + \n                   final_recall_score * score_weights[\"recall_at_10perc\"] + \n                   final_lift_score * score_weights[\"lift_at_10perc\"])\n    return final_score\n\n# =============================================================================\n# VERÄ° YÃœKLEME VE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°\n# =============================================================================\ndef load_data():\n    \"\"\"TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kler.\"\"\"\n    print(\"Veri setleri yÃ¼kleniyor...\")\n    customer_history = pd.read_csv('/kaggle/input/ing-hackathon-data/customer_history.csv', parse_dates=['date'])\n    customers = pd.read_csv('/kaggle/input/ing-hackathon-data/customers.csv')\n    train_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data.csv', parse_dates=['ref_date'])\n    test_ref = pd.read_csv('/kaggle/input/ing-hackathon-data/referance_data_test.csv', parse_dates=['ref_date'])\n    sample_submission = pd.read_csv('/kaggle/input/ing-hackathon-data/sample_submission.csv')\n    print(\"Veri setleri baÅŸarÄ±yla yÃ¼klendi.\")\n    return customer_history, customers, train_ref, test_ref, sample_submission\n\ndef feature_engineering(ref_df, customers_df, history_df, kmeans_model=None, scaler_health=None):\n    \"\"\"KapsamlÄ± ve birleÅŸtirilmiÅŸ \"ultimate\" Ã¶zellik mÃ¼hendisliÄŸi uygular.\"\"\"\n    print(f\"GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek {len(ref_df)} mÃ¼ÅŸteri var.\")\n    \n    df = pd.merge(ref_df, customers_df, on='cust_id', how='left')\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Student'), 'work_sector'] = 'Student'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Unemployed'), 'work_sector'] = 'Unemployed'\n    df.loc[(df['work_sector'].isnull()) & (df['work_type'] == 'Retired'), 'work_sector'] = 'Pension'\n\n    history = pd.merge(df[['cust_id', 'ref_date']], history_df, on='cust_id', how='left')\n    history = history[history['date'] <= history['ref_date']].copy()\n    \n    history['total_transaction_amt'] = history['mobile_eft_all_amt'] + history['cc_transaction_all_amt']\n    history['total_transaction_cnt'] = history['mobile_eft_all_cnt'] + history['cc_transaction_all_cnt']\n    history['months_before_ref'] = (history['ref_date'].dt.year - history['date'].dt.year) * 12 + (history['ref_date'].dt.month - history['date'].dt.month)\n\n    print(\"  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\")\n    aggs = {}\n    cols_to_agg = [\n        'mobile_eft_all_cnt', 'active_product_category_nbr', 'mobile_eft_all_amt', \n        'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'total_transaction_amt', \n        'total_transaction_cnt'\n    ]\n    stats_to_calc = ['mean', 'sum', 'std', 'min', 'max','median']\n    \n    for col in cols_to_agg:\n        aggs[col] = stats_to_calc\n    \n    grouped_all = history.groupby('cust_id').agg(aggs)\n    grouped_all.columns = ['_'.join(col).strip() + '_all' for col in grouped_all.columns.values]\n    df = pd.merge(df, grouped_all, on='cust_id', how='left')\n    \n    time_windows = [1, 3, 6, 9, 12, 15, 18, 24, 27]\n    for window in time_windows:\n        period_history = history[history['months_before_ref'] < window]\n        grouped_period = period_history.groupby('cust_id').agg(aggs)\n        grouped_period.columns = ['_'.join(col).strip() + f'_last_{window}m' for col in grouped_period.columns.values]\n        df = pd.merge(df, grouped_period, on='cust_id', how='left')\n\n    print(\"  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\")\n    for window in [1, 3, 6, 12]:\n        if f'total_transaction_amt_sum_last_{window*2}m' in df.columns:\n            df[f'transaction_growth_{window}m'] = (df[f'total_transaction_amt_sum_last_{window}m'] - df[f'total_transaction_amt_sum_last_{window*2}m']) / (df[f'total_transaction_amt_sum_last_{window*2}m'] + 1e-6)\n\n    df['ref_month'] = df['ref_date'].dt.month\n    df['ref_quarter'] = df['ref_date'].dt.quarter\n    df['is_year_end'] = df['ref_month'].isin([12, 1]).astype(int)\n\n    for col in ['total_transaction_amt', 'total_transaction_cnt']:\n        for window in [1,3, 6]:\n            mean_col = f'{col}_mean_last_{window}m'\n            std_col = f'{col}_std_last_{window}m'\n            current_col = f'{col}_sum_last_1m'\n            if mean_col in df.columns and std_col in df.columns and current_col in df.columns:\n                df[f'{col}_zscore_1m_vs_{window}m'] = (df[current_col] - df[mean_col]) / (df[std_col] + 1e-6)\n    \n    print(\"  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\")\n    last_transaction = history.groupby('cust_id')['date'].max().reset_index(name='last_transaction_date')\n    df = pd.merge(df, last_transaction, on='cust_id', how='left')\n    df['days_since_last_transaction'] = (df['ref_date'] - df['last_transaction_date']).dt.days\n    \n    first_transaction = history.groupby('cust_id')['date'].min().reset_index(name='first_transaction_date')\n    df = pd.merge(df, first_transaction, on='cust_id', how='left')\n\n    df['total_months_observed'] = ((df['ref_date'] - df['first_transaction_date']).dt.days / 30.44).round()\n    date_nunique = history.groupby('cust_id')['date'].nunique()\n    df['date_nunique_all'] = df['cust_id'].map(date_nunique)\n    \n    df['transaction_frequency_ratio'] = df['date_nunique_all'] / (df['total_months_observed'] + 1e-6)\n    df['inactive_months_count'] = df['total_months_observed'] - df['date_nunique_all']\n    df['banking_age'] = df['tenure'] - 17\n    df['avg_monetary_value_all'] = df['total_transaction_amt_sum_all'] / (df['total_transaction_cnt_sum_all'] + 1e-6)\n\n    rfm_cols = ['days_since_last_transaction', 'transaction_frequency_ratio', 'avg_monetary_value_all']\n    rfm_data = df[rfm_cols].fillna(0) \n\n    if kmeans_model is None:\n        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n        df['loyalty_tier'] = kmeans.fit_predict(rfm_data)\n        kmeans_model_to_return = kmeans\n    else: \n        df['loyalty_tier'] = kmeans_model.predict(rfm_data)\n        kmeans_model_to_return = None\n\n    print(\"  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\")\n    health_cols = {'pos': ['transaction_frequency_ratio'], 'neg': ['days_since_last_transaction', 'inactive_months_count']}\n    health_data = df[health_cols['pos'] + health_cols['neg']].fillna(0)\n\n    if scaler_health is None:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        health_scaled = scaler.fit_transform(health_data)\n        scaler_health_to_return = scaler\n    else:\n        health_scaled = scaler_health.transform(health_data)\n        scaler_health_to_return = None\n    \n    health_scaled_df = pd.DataFrame(health_scaled, index=df.index, columns=health_cols['pos'] + health_cols['neg'])\n    df['customer_health_score'] = health_scaled_df[health_cols['pos']].sum(axis=1) - health_scaled_df[health_cols['neg']].sum(axis=1)\n\n    bins_age = [17, 30, 45, 65, 120]; labels_age = ['young_adults', 'established_adults', 'prime_age_high_risk', 'senior']\n    df['age_group'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, right=True)\n    bins_tenure = [-1, 12, 36, 1200]; labels_tenure = ['new_customer', 'loyal_customer', 'veteran_customer']\n    df['tenure_group'] = pd.cut(df['tenure'], bins=bins_tenure, labels=labels_tenure, right=True)\n    \n    df['gender_x_age_group'] = df['gender'].astype(str) + '_' + df['age_group'].astype(str)\n    df['tenure_group_x_work_sector'] = df['tenure_group'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['province_x_work_sector'] = df['province'].astype(str) + '_' + df['work_sector'].astype(str)\n    df['religion_x_age_group'] = df['religion'].astype(str) + '_' + df['age_group'].astype(str)\n\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    cat_cols_final = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n    for col in cat_cols_final:\n        if isinstance(df[col].dtype, pd.CategoricalDtype):\n            if '-' not in df[col].cat.categories:\n                df[col] = df[col].cat.add_categories('-')\n            df[col] = df[col].fillna(\"-\")\n        else:\n            df[col] = pd.Categorical(df[col].fillna(\"-\"))\n\n    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n    df[numeric_cols] = df[numeric_cols].fillna(0)\n    \n    print(f\"Ã–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam {df.shape[1]} Ã¶zellik oluÅŸturuldu.\")\n    return df, kmeans_model_to_return, scaler_health_to_return\n\n# =============================================================================\n# Model EÄŸitimi ve Tahmin\n# =============================================================================\ndef optimize_and_train_catboost(train_df, test_df, sample_submission_df, n_trials_optuna=50):\n    \"\"\"Optuna ile optimize edilmiÅŸ CatBoost modeli eÄŸitir.\"\"\"\n    print(\"Nihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\")\n    \n    target = 'churn'\n    features_to_drop = ['cust_id', 'ref_date', target]\n    original_features = [col for col in train_df.columns if col not in features_to_drop]\n    \n    cat_cols_initial = [col for col in original_features if train_df[col].dtype == 'object' or isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    num_cols_initial = [col for col in original_features if col not in cat_cols_initial]\n\n    print(\"  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\")\n    for col in cat_cols_initial:\n        value_counts = train_df[col].value_counts()\n        rare_values = value_counts[value_counts < 25].index\n        \n        if 'rare' not in train_df[col].cat.categories:\n            train_df[col] = train_df[col].cat.add_categories('rare')\n        if 'rare' not in test_df[col].cat.categories:\n            test_df[col] = test_df[col].cat.add_categories('rare')\n\n        train_df[col] = train_df[col].replace(rare_values, 'rare')\n        test_df[col] = test_df[col].replace(rare_values, 'rare')\n\n    print(\"  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\")\n    corr_matrix = train_df[num_cols_initial].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] >= 0.96)]\n    \n    train_df = train_df.drop(columns=to_drop)\n    test_df = test_df.drop(columns=to_drop)\n    print(f\"    -> {len(to_drop)} Ã¶zellik kaldÄ±rÄ±ldÄ±.\")\n    \n    features = [col for col in train_df.columns if col not in features_to_drop]\n    cat_cols = [col for col in features if isinstance(train_df[col].dtype, pd.CategoricalDtype)]\n    \n    # Optuna Objective Function\n    def objective(trial):\n        params = {\n            'iterations': 6000,\n            'depth': trial.suggest_int('depth', 5, 9),\n            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n            'max_bin': trial.suggest_int('max_bin', 32, 128),\n            'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n            'allow_writing_files': False,\n            'random_state': 0,\n            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 1.0)\n        }\n        \n        cv_opt = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n        scores = []\n        for train_idx, val_idx in cv_opt.split(train_df, train_df[target]):\n            X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n            X_val_fold = train_df.iloc[val_idx].copy()\n            \n            global_mean_fold = y_train_fold.mean()\n            alpha = 5\n            for col in cat_cols:\n                counts = X_train_fold[col].value_counts()\n                means = y_train_fold.groupby(X_train_fold[col]).mean()\n                smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n                \n                X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n                X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n            \n            model = CatBoostClassifier(**params)\n            model.fit(X_train_fold[features], y_train_fold,\n                      eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                      early_stopping_rounds=100, verbose=0)\n            \n            preds = model.predict_proba(X_val_fold[features])[:, 1]\n            scores.append(ing_hubs_datathon_metric(train_df[target].iloc[val_idx], preds))\n        return np.mean(scores)\n\n    print(f\"\\nOptuna ile optimizasyon baÅŸlÄ±yor ({n_trials_optuna} deneme)...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=n_trials_optuna)\n    best_params = study.best_params\n    print(\"\\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu:\", best_params)\n\n    # Final Model EÄŸitimi\n    final_model_params = {\n        'iterations': 6000,\n        **best_params \n    }\n\n    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=1)\n    oof_preds = np.zeros(len(train_df))\n    test_preds = np.zeros(len(test_df))\n    \n    # SHAP iÃ§in Ã¶zellik Ã¶nemlerini topla\n    all_fold_importances = []\n    \n    test_df_encoded = test_df.copy()\n    global_mean_full = train_df[target].mean()\n    alpha = 5\n    for col in cat_cols:\n        counts = train_df[col].value_counts()\n        means = train_df[target].groupby(train_df[col]).mean()\n        smooth_means = (means * counts + global_mean_full * alpha) / (counts + alpha)\n        test_df_encoded[col] = test_df_encoded[col].map(smooth_means).astype(float).fillna(global_mean_full)\n\n    print(f\"\\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\")\n    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[target])):\n        print(f\"===== Fold {fold+1} =====\")\n        \n        X_train_fold, y_train_fold = train_df.iloc[train_idx].copy(), train_df[target].iloc[train_idx]\n        X_val_fold = train_df.iloc[val_idx].copy()\n        \n        global_mean_fold = y_train_fold.mean()\n        for col in cat_cols:\n            counts = X_train_fold[col].value_counts()\n            means = y_train_fold.groupby(X_train_fold[col]).mean()\n            smooth_means = (means * counts + global_mean_fold * alpha) / (counts + alpha)\n            \n            X_train_fold[col] = X_train_fold[col].map(smooth_means).astype(float)\n            X_val_fold[col] = X_val_fold[col].map(smooth_means).astype(float).fillna(global_mean_fold)\n        \n        model = CatBoostClassifier(**final_model_params)\n        model.fit(X_train_fold[features], y_train_fold,\n                  eval_set=(X_val_fold[features], train_df[target].iloc[val_idx]),\n                  early_stopping_rounds=40,\n                  verbose=500)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val_fold[features])[:, 1]\n        test_preds += model.predict_proba(test_df_encoded[features])[:, 1] / cv.n_splits\n        all_fold_importances.append(model.get_feature_importance())\n        \n        del X_train_fold, y_train_fold, X_val_fold\n        gc.collect()\n\n    final_oof_score = ing_hubs_datathon_metric(train_df[target], oof_preds)\n    print(\"\\n==============================================\")\n    print(f\"Final OOF Skoru (Kalibrasyon Ã–ncesi): {final_oof_score:.5f}\")\n    \n    print(\"  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\")\n    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n    iso_reg.fit(oof_preds, train_df[target])\n    calibrated_test_preds = iso_reg.transform(test_preds)\n\n    calibrated_oof_score = ing_hubs_datathon_metric(train_df[target], iso_reg.transform(oof_preds))\n    print(f\"Final OOF Skoru (Kalibrasyon SonrasÄ±): {calibrated_oof_score:.5f}\")\n    print(\"==============================================\")\n    \n    # SHAP Ã–zet GrafiÄŸi\n    print(\"\\nSHAP DeÄŸerleri HesaplanÄ±yor ve Grafik Ã‡iziliyor...\")\n    mean_importances = np.mean(all_fold_importances, axis=0)\n    importance_df = pd.DataFrame({'feature': features, 'importance': mean_importances})\n    importance_df = importance_df.sort_values(by='importance', ascending=False).head(150)\n\n    plt.figure(figsize=(10, 8))\n    plt.barh(importance_df['feature'], importance_df['importance'])\n    plt.xlabel(\"Ortalama Ã–zellik Ã–nem Derecesi (Feature Importance)\")\n    plt.ylabel(\"Ã–zellikler\")\n    plt.title(\"En Ã–nemli 20 Ã–zellik (CatBoost)\")\n    plt.gca().invert_yaxis()\n    plt.tight_layout()\n    plt.show()\n    \n    submission_df = sample_submission_df.copy()\n    submission_df['churn'] = calibrated_test_preds\n    submission_df.to_csv('submission_catboost_calibrated.csv', index=False)\n    \n    print(\"\\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\")\n    return submission_df\n\n# =============================================================================\n# Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu\n# =============================================================================\nif __name__ == \"__main__\":\n    customer_history, customers, train_ref, test_ref, sample_submission = load_data()\n    \n    train_featured, kmeans_model, scaler_health = feature_engineering(train_ref, customers, customer_history)\n    test_featured, _, _ = feature_engineering(test_ref, customers, customer_history, kmeans_model=kmeans_model, scaler_health=scaler_health)\n    \n    del customer_history, customers, train_ref, test_ref\n    gc.collect()\n\n    submission = optimize_and_train_catboost(train_featured, test_featured, sample_submission, n_trials_optuna=100)\n    \n    print(\"\\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\")\n    print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T20:48:27.186107Z","iopub.execute_input":"2025-10-21T20:48:27.186879Z","iopub.status.idle":"2025-10-22T04:39:49.947366Z","shell.execute_reply.started":"2025-10-21T20:48:27.186850Z","shell.execute_reply":"2025-10-22T04:39:49.945842Z"}},"outputs":[{"name":"stdout","text":"Veri setleri yÃ¼kleniyor...\nVeri setleri baÅŸarÄ±yla yÃ¼klendi.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 133287 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 459 Ã¶zellik oluÅŸturuldu.\nGeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi baÅŸlÄ±yor. Ä°ÅŸlenecek 43006 mÃ¼ÅŸteri var.\n  -> Zaman bazlÄ± agregasyon Ã¶zellikleri oluÅŸturuluyor...\n  -> BÃ¼yÃ¼me, mevsimsellik ve anomali Ã¶zellikleri oluÅŸturuluyor...\n  -> RFM ve diÄŸer davranÄ±ÅŸsal Ã¶zellikler ekleniyor...\n  -> MÃ¼ÅŸteri SaÄŸlÄ±k Skoru oluÅŸturuluyor...\nÃ–zellik mÃ¼hendisliÄŸi tamamlandÄ±. Toplam 458 Ã¶zellik oluÅŸturuldu.\nNihai CatBoost modeli eÄŸitim sÃ¼reci baÅŸlÄ±yor...\n  -> Nadir kategoriler 'rare' olarak birleÅŸtiriliyor...\n  -> YÃ¼ksek korelasyonlu Ã¶zellikler kaldÄ±rÄ±lÄ±yor...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-10-21 20:50:38,064] A new study created in memory with name: no-name-3f61a5e6-7555-4646-8236-481f42557c3b\n","output_type":"stream"},{"name":"stdout","text":"    -> 325 Ã¶zellik kaldÄ±rÄ±ldÄ±.\n\nOptuna ile optimizasyon baÅŸlÄ±yor (100 deneme)...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-10-21 20:52:15,062] Trial 0 finished with value: 1.1671076114139112 and parameters: {'depth': 6, 'learning_rate': 0.03282825256427306, 'l2_leaf_reg': 3.71893422992606, 'max_bin': 70, 'random_strength': 1.3025369686901733, 'bagging_temperature': 0.8592355570411202}. Best is trial 0 with value: 1.1671076114139112.\n[I 2025-10-21 21:01:09,007] Trial 1 finished with value: 1.1803992999519524 and parameters: {'depth': 9, 'learning_rate': 0.006360304308203812, 'l2_leaf_reg': 4.755659230419006, 'max_bin': 80, 'random_strength': 1.2901428324423598, 'bagging_temperature': 0.9627669081785851}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:05:34,951] Trial 2 finished with value: 1.1793006632952814 and parameters: {'depth': 7, 'learning_rate': 0.012761182009485082, 'l2_leaf_reg': 2.715360990755919, 'max_bin': 119, 'random_strength': 4.930795489404435, 'bagging_temperature': 0.5516404685807748}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:06:48,663] Trial 3 finished with value: 1.1690477738741774 and parameters: {'depth': 6, 'learning_rate': 0.04816060685711581, 'l2_leaf_reg': 8.770651063906021, 'max_bin': 117, 'random_strength': 7.6744637798497, 'bagging_temperature': 0.3419651390497274}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:08:11,846] Trial 4 finished with value: 1.1629418737444868 and parameters: {'depth': 8, 'learning_rate': 0.04250545242239627, 'l2_leaf_reg': 2.0259321321701806, 'max_bin': 83, 'random_strength': 4.235556783390942, 'bagging_temperature': 0.2322797177739991}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:13:17,799] Trial 5 finished with value: 1.1761810916272282 and parameters: {'depth': 7, 'learning_rate': 0.009526243256323605, 'l2_leaf_reg': 2.5408341146735194, 'max_bin': 57, 'random_strength': 5.3294175914184505, 'bagging_temperature': 0.6424910274939435}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:14:54,193] Trial 6 finished with value: 1.172573147321245 and parameters: {'depth': 6, 'learning_rate': 0.04109452120648029, 'l2_leaf_reg': 1.2494185587370255, 'max_bin': 110, 'random_strength': 5.856345575279827, 'bagging_temperature': 0.522053535149774}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:24:12,457] Trial 7 finished with value: 1.1752163968167522 and parameters: {'depth': 9, 'learning_rate': 0.008793760961631045, 'l2_leaf_reg': 5.089389993633807, 'max_bin': 118, 'random_strength': 8.72357138549423, 'bagging_temperature': 0.19125809339479416}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:25:24,294] Trial 8 finished with value: 1.1737064104266022 and parameters: {'depth': 5, 'learning_rate': 0.04730235534200074, 'l2_leaf_reg': 5.4147075860770775, 'max_bin': 72, 'random_strength': 4.968158828427768, 'bagging_temperature': 0.10470035011777992}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:28:06,199] Trial 9 finished with value: 1.1760600774634986 and parameters: {'depth': 6, 'learning_rate': 0.0184599985115978, 'l2_leaf_reg': 1.0040024927003914, 'max_bin': 48, 'random_strength': 6.632030198496452, 'bagging_temperature': 0.14581953053481622}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:51:21,728] Trial 10 finished with value: 1.175440399171235 and parameters: {'depth': 9, 'learning_rate': 0.0012784714062900127, 'l2_leaf_reg': 8.400667845364689, 'max_bin': 34, 'random_strength': 1.3012755644749523, 'bagging_temperature': 0.9847579595293332}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:54:26,703] Trial 11 finished with value: 1.1631665130236664 and parameters: {'depth': 8, 'learning_rate': 0.019272905482660186, 'l2_leaf_reg': 3.787542614673914, 'max_bin': 96, 'random_strength': 3.0309549864360186, 'bagging_temperature': 0.7129464673471656}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 21:59:41,257] Trial 12 finished with value: 1.176451923219431 and parameters: {'depth': 8, 'learning_rate': 0.009806446711820344, 'l2_leaf_reg': 6.939607105275523, 'max_bin': 94, 'random_strength': 3.225832160263298, 'bagging_temperature': 0.40428074441635264}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:14:03,443] Trial 13 finished with value: 1.1704090105411284 and parameters: {'depth': 7, 'learning_rate': 0.0015475774912928428, 'l2_leaf_reg': 3.714545669040198, 'max_bin': 99, 'random_strength': 2.895308932856655, 'bagging_temperature': 0.8128777783495328}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:17:17,479] Trial 14 finished with value: 1.1777387204834149 and parameters: {'depth': 8, 'learning_rate': 0.02013048923720566, 'l2_leaf_reg': 6.912417077194503, 'max_bin': 128, 'random_strength': 9.257590002338256, 'bagging_temperature': 0.5585190674918123}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:19:47,804] Trial 15 finished with value: 1.1674013220388126 and parameters: {'depth': 9, 'learning_rate': 0.030397528840345217, 'l2_leaf_reg': 4.6725291430621985, 'max_bin': 81, 'random_strength': 7.063022252704434, 'bagging_temperature': 0.9754984144933346}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:23:23,456] Trial 16 finished with value: 1.1731535679435368 and parameters: {'depth': 7, 'learning_rate': 0.012750077779589896, 'l2_leaf_reg': 6.844533361333786, 'max_bin': 69, 'random_strength': 2.3978572194840906, 'bagging_temperature': 0.7444756103488903}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:27:12,214] Trial 17 finished with value: 1.1752895800219474 and parameters: {'depth': 8, 'learning_rate': 0.014866557376792712, 'l2_leaf_reg': 2.661268290239817, 'max_bin': 105, 'random_strength': 4.218288266523585, 'bagging_temperature': 0.44917498268744543}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:34:33,893] Trial 18 finished with value: 1.1763204337397648 and parameters: {'depth': 5, 'learning_rate': 0.005795910306396632, 'l2_leaf_reg': 6.097777150625051, 'max_bin': 88, 'random_strength': 1.9894402701790046, 'bagging_temperature': 0.28562763396489166}. Best is trial 1 with value: 1.1803992999519524.\n[I 2025-10-21 22:36:35,053] Trial 19 finished with value: 1.1810765878429639 and parameters: {'depth': 7, 'learning_rate': 0.02499651068043169, 'l2_leaf_reg': 9.80533396785614, 'max_bin': 57, 'random_strength': 8.16859210701793, 'bagging_temperature': 0.618517454284633}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:39:06,197] Trial 20 finished with value: 1.1752089586892787 and parameters: {'depth': 9, 'learning_rate': 0.026220360755448723, 'l2_leaf_reg': 9.695881643109255, 'max_bin': 55, 'random_strength': 8.523897213650478, 'bagging_temperature': 0.8746877369504716}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:41:20,976] Trial 21 finished with value: 1.17347061469189 and parameters: {'depth': 7, 'learning_rate': 0.023592611489479717, 'l2_leaf_reg': 4.289152481737465, 'max_bin': 36, 'random_strength': 9.696322962390976, 'bagging_temperature': 0.6125186544383763}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:42:59,040] Trial 22 finished with value: 1.170433690489823 and parameters: {'depth': 7, 'learning_rate': 0.034121289261543696, 'l2_leaf_reg': 2.974144443520388, 'max_bin': 61, 'random_strength': 6.361391866860876, 'bagging_temperature': 0.6558384379925623}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:46:19,133] Trial 23 finished with value: 1.1776060820875134 and parameters: {'depth': 7, 'learning_rate': 0.014906821143434543, 'l2_leaf_reg': 7.9351657769760795, 'max_bin': 44, 'random_strength': 7.418307045603382, 'bagging_temperature': 0.4430225768530869}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:54:21,136] Trial 24 finished with value: 1.173873805364215 and parameters: {'depth': 6, 'learning_rate': 0.0054519760990958755, 'l2_leaf_reg': 9.645604189022443, 'max_bin': 76, 'random_strength': 4.288012610019795, 'bagging_temperature': 0.7496925816616542}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 22:56:27,346] Trial 25 finished with value: 1.1708803187033852 and parameters: {'depth': 8, 'learning_rate': 0.02669810111124344, 'l2_leaf_reg': 5.870105818732206, 'max_bin': 65, 'random_strength': 8.088314404869998, 'bagging_temperature': 0.5564188412924073}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:02:52,218] Trial 26 finished with value: 1.1763501987481628 and parameters: {'depth': 7, 'learning_rate': 0.0063184282537077805, 'l2_leaf_reg': 1.7216759500756105, 'max_bin': 49, 'random_strength': 3.719112759697434, 'bagging_temperature': 0.8961301651163531}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:06:53,435] Trial 27 finished with value: 1.1723205941516452 and parameters: {'depth': 7, 'learning_rate': 0.013460508312551557, 'l2_leaf_reg': 3.095857444474689, 'max_bin': 87, 'random_strength': 9.99265659678823, 'bagging_temperature': 0.032187246648130774}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:09:41,115] Trial 28 finished with value: 1.180046306480213 and parameters: {'depth': 8, 'learning_rate': 0.023074326960918566, 'l2_leaf_reg': 4.382698438085934, 'max_bin': 105, 'random_strength': 6.154943496571767, 'bagging_temperature': 0.36019230218094844}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:12:16,503] Trial 29 finished with value: 1.1698549694009102 and parameters: {'depth': 9, 'learning_rate': 0.031084503811892414, 'l2_leaf_reg': 6.217716366050747, 'max_bin': 106, 'random_strength': 5.849675370402042, 'bagging_temperature': 0.3223767094734636}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:13:52,697] Trial 30 finished with value: 1.1742568953578079 and parameters: {'depth': 8, 'learning_rate': 0.0362510927848453, 'l2_leaf_reg': 4.42497890395782, 'max_bin': 90, 'random_strength': 6.61235584455792, 'bagging_temperature': 0.3981491358760928}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:16:51,164] Trial 31 finished with value: 1.1762829233483953 and parameters: {'depth': 8, 'learning_rate': 0.022281574949343495, 'l2_leaf_reg': 3.6428911691809818, 'max_bin': 122, 'random_strength': 5.093479460220709, 'bagging_temperature': 0.473337877314746}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:19:33,170] Trial 32 finished with value: 1.1707824202395019 and parameters: {'depth': 9, 'learning_rate': 0.028652844063153233, 'l2_leaf_reg': 4.7857171345783875, 'max_bin': 112, 'random_strength': 7.842435212463208, 'bagging_temperature': 0.8183112750946473}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:22:26,812] Trial 33 finished with value: 1.1769269341736195 and parameters: {'depth': 6, 'learning_rate': 0.016119965122971768, 'l2_leaf_reg': 3.9529406768992956, 'max_bin': 128, 'random_strength': 2.1281079898940245, 'bagging_temperature': 0.5930755943505697}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:24:23,192] Trial 34 finished with value: 1.1760050090588672 and parameters: {'depth': 8, 'learning_rate': 0.022860815130674995, 'l2_leaf_reg': 2.0936668285927245, 'max_bin': 104, 'random_strength': 1.0865873003797304, 'bagging_temperature': 0.2593113001472748}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:28:33,519] Trial 35 finished with value: 1.1780692210587072 and parameters: {'depth': 7, 'learning_rate': 0.011746423022030463, 'l2_leaf_reg': 3.264104418750482, 'max_bin': 115, 'random_strength': 4.6223560984175265, 'bagging_temperature': 0.35989912613581554}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:30:03,327] Trial 36 finished with value: 1.1643632231595606 and parameters: {'depth': 8, 'learning_rate': 0.03773802054699593, 'l2_leaf_reg': 5.407234534656224, 'max_bin': 76, 'random_strength': 5.813203229802438, 'bagging_temperature': 0.511702852523121}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:32:54,257] Trial 37 finished with value: 1.1768950784622738 and parameters: {'depth': 6, 'learning_rate': 0.017724922761906105, 'l2_leaf_reg': 2.3572793881957828, 'max_bin': 121, 'random_strength': 8.767366765835975, 'bagging_temperature': 0.6873261149591704}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:46:37,801] Trial 38 finished with value: 1.1730974485382377 and parameters: {'depth': 9, 'learning_rate': 0.004447096004415686, 'l2_leaf_reg': 1.5755945450781097, 'max_bin': 98, 'random_strength': 7.138295495788049, 'bagging_temperature': 0.33424597013419366}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:51:39,263] Trial 39 finished with value: 1.176736779212659 and parameters: {'depth': 7, 'learning_rate': 0.010168779083863768, 'l2_leaf_reg': 4.964844191044291, 'max_bin': 109, 'random_strength': 3.690567678586971, 'bagging_temperature': 0.9234565744824602}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-21 23:57:18,898] Trial 40 finished with value: 1.1803058828108253 and parameters: {'depth': 6, 'learning_rate': 0.007987879039796256, 'l2_leaf_reg': 8.978814909816473, 'max_bin': 83, 'random_strength': 5.406297395502049, 'bagging_temperature': 0.806536101881079}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:02:41,274] Trial 41 finished with value: 1.1749249389822074 and parameters: {'depth': 5, 'learning_rate': 0.00855517675531712, 'l2_leaf_reg': 9.285706501962572, 'max_bin': 69, 'random_strength': 5.438639932800489, 'bagging_temperature': 0.9411813735271369}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:05:14,364] Trial 42 finished with value: 1.1750739380541344 and parameters: {'depth': 6, 'learning_rate': 0.02104150717190066, 'l2_leaf_reg': 9.008023478184098, 'max_bin': 84, 'random_strength': 6.146940963280788, 'bagging_temperature': 0.8153723258748444}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:10:48,258] Trial 43 finished with value: 1.177257606353728 and parameters: {'depth': 6, 'learning_rate': 0.008458770664997489, 'l2_leaf_reg': 8.122757550989933, 'max_bin': 77, 'random_strength': 4.700339992892092, 'bagging_temperature': 0.775019368613312}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:23:04,713] Trial 44 finished with value: 1.1749153712798306 and parameters: {'depth': 7, 'learning_rate': 0.0035633549297224565, 'l2_leaf_reg': 8.949878614154263, 'max_bin': 56, 'random_strength': 6.986545970744862, 'bagging_temperature': 0.6629493904499147}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:26:28,501] Trial 45 finished with value: 1.176403757892894 and parameters: {'depth': 6, 'learning_rate': 0.016725195730510727, 'l2_leaf_reg': 9.859699466513957, 'max_bin': 93, 'random_strength': 8.273908076247245, 'bagging_temperature': 0.5550674067402441}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:36:29,249] Trial 46 finished with value: 1.1659377937370314 and parameters: {'depth': 5, 'learning_rate': 0.0021954514671149623, 'l2_leaf_reg': 7.454592850422148, 'max_bin': 116, 'random_strength': 5.537475627982209, 'bagging_temperature': 0.623372333447236}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:37:47,467] Trial 47 finished with value: 1.1691796307897948 and parameters: {'depth': 8, 'learning_rate': 0.04469815131785243, 'l2_leaf_reg': 8.67044957081439, 'max_bin': 123, 'random_strength': 1.6888411289630834, 'bagging_temperature': 0.9923960626525863}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:46:10,988] Trial 48 finished with value: 1.1692945293427965 and parameters: {'depth': 9, 'learning_rate': 0.007168662220946125, 'l2_leaf_reg': 5.351348791128538, 'max_bin': 63, 'random_strength': 9.03651575614457, 'bagging_temperature': 0.8545346917271514}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:50:20,254] Trial 49 finished with value: 1.179358417847405 and parameters: {'depth': 7, 'learning_rate': 0.01144852405005531, 'l2_leaf_reg': 7.323876316641488, 'max_bin': 99, 'random_strength': 3.621380342332409, 'bagging_temperature': 0.1837722382391699}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:54:34,791] Trial 50 finished with value: 1.178649403018157 and parameters: {'depth': 7, 'learning_rate': 0.012004963890784148, 'l2_leaf_reg': 7.315302352974945, 'max_bin': 99, 'random_strength': 2.7315917435101094, 'bagging_temperature': 0.11382431532137444}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 00:59:21,069] Trial 51 finished with value: 1.1726747383522385 and parameters: {'depth': 7, 'learning_rate': 0.010238563447012437, 'l2_leaf_reg': 8.40491720602063, 'max_bin': 100, 'random_strength': 3.557049983632448, 'bagging_temperature': 0.23314924946313917}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:01:53,376] Trial 52 finished with value: 1.1729392454232093 and parameters: {'depth': 7, 'learning_rate': 0.019286518223632622, 'l2_leaf_reg': 9.226840248868747, 'max_bin': 92, 'random_strength': 4.05162126744646, 'bagging_temperature': 0.18204308458730994}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:05:39,065] Trial 53 finished with value: 1.1727522583878776 and parameters: {'depth': 7, 'learning_rate': 0.013812314406810787, 'l2_leaf_reg': 6.587765393982274, 'max_bin': 102, 'random_strength': 4.695615804182499, 'bagging_temperature': 0.4887287895033536}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:13:18,176] Trial 54 finished with value: 1.1777672888303539 and parameters: {'depth': 8, 'learning_rate': 0.0076455963593274785, 'l2_leaf_reg': 9.981713155402165, 'max_bin': 86, 'random_strength': 5.052563607028833, 'bagging_temperature': 0.40403195523866553}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:15:07,821] Trial 55 finished with value: 1.1749634631318318 and parameters: {'depth': 6, 'learning_rate': 0.02821234896824549, 'l2_leaf_reg': 5.774161430975449, 'max_bin': 111, 'random_strength': 6.203693012834013, 'bagging_temperature': 0.7115818881888472}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:16:58,492] Trial 56 finished with value: 1.1717920424750374 and parameters: {'depth': 8, 'learning_rate': 0.025227820733883067, 'l2_leaf_reg': 7.71423331267059, 'max_bin': 81, 'random_strength': 1.4928347158389665, 'bagging_temperature': 0.016753144607110027}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:28:54,070] Trial 57 finished with value: 1.1764807191138997 and parameters: {'depth': 7, 'learning_rate': 0.0035642976464446453, 'l2_leaf_reg': 4.100231786952103, 'max_bin': 73, 'random_strength': 2.54646549499437, 'bagging_temperature': 0.07372640316491463}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:33:01,661] Trial 58 finished with value: 1.1744981868176705 and parameters: {'depth': 5, 'learning_rate': 0.010799248344872102, 'l2_leaf_reg': 3.440688739121834, 'max_bin': 39, 'random_strength': 3.186433144166093, 'bagging_temperature': 0.9524247656215242}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:35:07,543] Trial 59 finished with value: 1.170919742205804 and parameters: {'depth': 6, 'learning_rate': 0.02458069184721921, 'l2_leaf_reg': 9.524192865882288, 'max_bin': 51, 'random_strength': 6.694516576234049, 'bagging_temperature': 0.5262794744212845}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:38:54,521] Trial 60 finished with value: 1.1667667625780855 and parameters: {'depth': 9, 'learning_rate': 0.02107713121887951, 'l2_leaf_reg': 4.423902217484064, 'max_bin': 107, 'random_strength': 7.566691983344577, 'bagging_temperature': 0.29491968407734104}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:43:00,873] Trial 61 finished with value: 1.1782219168722083 and parameters: {'depth': 7, 'learning_rate': 0.012201913227553422, 'l2_leaf_reg': 6.386071998210978, 'max_bin': 96, 'random_strength': 2.579180130575695, 'bagging_temperature': 0.14317853672227573}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:46:27,402] Trial 62 finished with value: 1.176032668687043 and parameters: {'depth': 7, 'learning_rate': 0.01544175132589308, 'l2_leaf_reg': 7.180266737497971, 'max_bin': 103, 'random_strength': 2.8560239880307883, 'bagging_temperature': 0.1036112779219563}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:50:06,726] Trial 63 finished with value: 1.1744941066429542 and parameters: {'depth': 7, 'learning_rate': 0.013540331109911648, 'l2_leaf_reg': 8.665000599248737, 'max_bin': 113, 'random_strength': 1.9847875046962378, 'bagging_temperature': 0.1569246837730253}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 01:53:11,460] Trial 64 finished with value: 1.1749795107483523 and parameters: {'depth': 7, 'learning_rate': 0.017842156591889216, 'l2_leaf_reg': 7.25838339913822, 'max_bin': 97, 'random_strength': 4.060106839262325, 'bagging_temperature': 0.21899263103290903}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:01:43,455] Trial 65 finished with value: 1.174990360131462 and parameters: {'depth': 7, 'learning_rate': 0.005809450999775153, 'l2_leaf_reg': 8.124526274324303, 'max_bin': 119, 'random_strength': 3.3033061077056787, 'bagging_temperature': 0.06178088019288014}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:06:40,646] Trial 66 finished with value: 1.1724270448735823 and parameters: {'depth': 8, 'learning_rate': 0.010928053280418225, 'l2_leaf_reg': 5.192139436191294, 'max_bin': 89, 'random_strength': 4.324187084452998, 'bagging_temperature': 0.4354927380514286}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:12:18,379] Trial 67 finished with value: 1.1792009185320242 and parameters: {'depth': 8, 'learning_rate': 0.009162832170100912, 'l2_leaf_reg': 5.940855089692097, 'max_bin': 108, 'random_strength': 5.266645849855199, 'bagging_temperature': 0.7768788541145909}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:30:25,273] Trial 68 finished with value: 1.1682472435333875 and parameters: {'depth': 8, 'learning_rate': 0.0012395042711842927, 'l2_leaf_reg': 2.809325912146871, 'max_bin': 108, 'random_strength': 5.640885809831381, 'bagging_temperature': 0.7680378683989512}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:32:22,415] Trial 69 finished with value: 1.1630978564929675 and parameters: {'depth': 9, 'learning_rate': 0.033288057549803865, 'l2_leaf_reg': 5.755384112848565, 'max_bin': 60, 'random_strength': 5.329595591777504, 'bagging_temperature': 0.855266360234831}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:38:10,898] Trial 70 finished with value: 1.1780629553663735 and parameters: {'depth': 8, 'learning_rate': 0.009343741656318325, 'l2_leaf_reg': 6.001506505404739, 'max_bin': 114, 'random_strength': 5.0207822684819305, 'bagging_temperature': 0.7342273046543079}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:45:51,101] Trial 71 finished with value: 1.1765579116907474 and parameters: {'depth': 7, 'learning_rate': 0.0069495420483415525, 'l2_leaf_reg': 4.6386382883213235, 'max_bin': 100, 'random_strength': 6.00838637629374, 'bagging_temperature': 0.582995771812161}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 02:49:10,792] Trial 72 finished with value: 1.1774501044356247 and parameters: {'depth': 7, 'learning_rate': 0.012604887297228883, 'l2_leaf_reg': 6.64033181013429, 'max_bin': 94, 'random_strength': 1.0175789906957895, 'bagging_temperature': 0.6363187076335166}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:02:31,051] Trial 73 finished with value: 1.1733722654904872 and parameters: {'depth': 9, 'learning_rate': 0.004507781781157555, 'l2_leaf_reg': 7.7940452049647755, 'max_bin': 66, 'random_strength': 4.479542001627667, 'bagging_temperature': 0.3604559214575847}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:05:47,460] Trial 74 finished with value: 1.174035017449999 and parameters: {'depth': 7, 'learning_rate': 0.014349069387875422, 'l2_leaf_reg': 1.0457472864054158, 'max_bin': 102, 'random_strength': 2.215359198736862, 'bagging_temperature': 0.6823129420653824}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:11:21,573] Trial 75 finished with value: 1.1775033783091315 and parameters: {'depth': 8, 'learning_rate': 0.01158561141925473, 'l2_leaf_reg': 4.9563212261944765, 'max_bin': 124, 'random_strength': 3.5750511140108747, 'bagging_temperature': 0.9052204001410288}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:17:04,802] Trial 76 finished with value: 1.1783895260632689 and parameters: {'depth': 7, 'learning_rate': 0.008623426367963514, 'l2_leaf_reg': 9.471250785059405, 'max_bin': 105, 'random_strength': 6.520474206187851, 'bagging_temperature': 0.11691719265648427}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:18:47,699] Trial 77 finished with value: 1.180221046972675 and parameters: {'depth': 8, 'learning_rate': 0.029625112786834978, 'l2_leaf_reg': 5.6277273072427105, 'max_bin': 109, 'random_strength': 1.6790100053418593, 'bagging_temperature': 0.5352838359141044}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:20:30,993] Trial 78 finished with value: 1.178390394590159 and parameters: {'depth': 8, 'learning_rate': 0.02951946752280092, 'l2_leaf_reg': 5.531430096278935, 'max_bin': 117, 'random_strength': 1.794054962681436, 'bagging_temperature': 0.5935197622308823}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:22:02,745] Trial 79 finished with value: 1.1769547918749756 and parameters: {'depth': 8, 'learning_rate': 0.03635627798727117, 'l2_leaf_reg': 4.171306725800554, 'max_bin': 126, 'random_strength': 1.526435998996033, 'bagging_temperature': 0.5401023226478263}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:24:11,453] Trial 80 finished with value: 1.1774783220195812 and parameters: {'depth': 8, 'learning_rate': 0.03139046351023241, 'l2_leaf_reg': 6.3150686292033855, 'max_bin': 119, 'random_strength': 3.964815190103479, 'bagging_temperature': 0.46690477301164873}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:25:57,920] Trial 81 finished with value: 1.1778743756181356 and parameters: {'depth': 6, 'learning_rate': 0.026140749815909137, 'l2_leaf_reg': 6.896374390276263, 'max_bin': 110, 'random_strength': 2.7471915534286877, 'bagging_temperature': 0.7910518297354453}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:28:46,851] Trial 82 finished with value: 1.1732744793414576 and parameters: {'depth': 8, 'learning_rate': 0.02352914858173971, 'l2_leaf_reg': 4.6851004550809, 'max_bin': 107, 'random_strength': 5.212704772637808, 'bagging_temperature': 0.4927269831329074}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:30:11,377] Trial 83 finished with value: 1.1718439183299318 and parameters: {'depth': 7, 'learning_rate': 0.028152089881809728, 'l2_leaf_reg': 3.762702880395506, 'max_bin': 44, 'random_strength': 1.4057061137370799, 'bagging_temperature': 0.5915414350729449}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:33:43,248] Trial 84 finished with value: 1.179223123732126 and parameters: {'depth': 9, 'learning_rate': 0.01673959907493923, 'l2_leaf_reg': 5.5684188523328775, 'max_bin': 84, 'random_strength': 2.2948591909588876, 'bagging_temperature': 0.4277856079593372}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:35:48,045] Trial 85 finished with value: 1.1772816986892165 and parameters: {'depth': 9, 'learning_rate': 0.02712880382486784, 'l2_leaf_reg': 5.628464947141146, 'max_bin': 83, 'random_strength': 1.175773784674449, 'bagging_temperature': 0.3699205751254013}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:38:31,102] Trial 86 finished with value: 1.1664647426273496 and parameters: {'depth': 9, 'learning_rate': 0.02105583666469274, 'l2_leaf_reg': 5.1589426265841265, 'max_bin': 78, 'random_strength': 1.8014102340117617, 'bagging_temperature': 0.44400791447540106}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:46:50,501] Trial 87 finished with value: 1.1754888844032125 and parameters: {'depth': 9, 'learning_rate': 0.007418047903500801, 'l2_leaf_reg': 5.3273447950430874, 'max_bin': 73, 'random_strength': 4.823218549961188, 'bagging_temperature': 0.8782258123705696}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:50:34,679] Trial 88 finished with value: 1.171027636234819 and parameters: {'depth': 9, 'learning_rate': 0.017106523222711074, 'l2_leaf_reg': 5.97642583740202, 'max_bin': 91, 'random_strength': 2.362735864225983, 'bagging_temperature': 0.42673019496507125}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:55:14,459] Trial 89 finished with value: 1.177424405878434 and parameters: {'depth': 9, 'learning_rate': 0.015155093788735152, 'l2_leaf_reg': 4.879104199341494, 'max_bin': 84, 'random_strength': 5.781815558177707, 'bagging_temperature': 0.5668662577886553}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 03:58:23,977] Trial 90 finished with value: 1.1707083203011293 and parameters: {'depth': 8, 'learning_rate': 0.018574875026060866, 'l2_leaf_reg': 2.3869029293947186, 'max_bin': 86, 'random_strength': 9.284555779757824, 'bagging_temperature': 0.4696369913069911}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:03:23,237] Trial 91 finished with value: 1.1795241361264037 and parameters: {'depth': 7, 'learning_rate': 0.009948669280390243, 'l2_leaf_reg': 6.572150463224494, 'max_bin': 99, 'random_strength': 2.1128292070736125, 'bagging_temperature': 0.30858413355006215}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:07:53,786] Trial 92 finished with value: 1.1770488084203985 and parameters: {'depth': 7, 'learning_rate': 0.009202378915039599, 'l2_leaf_reg': 6.414963615984156, 'max_bin': 95, 'random_strength': 1.3263972599399856, 'bagging_temperature': 0.28955762766657006}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:20:26,573] Trial 93 finished with value: 1.1773001276228514 and parameters: {'depth': 9, 'learning_rate': 0.004769626932975725, 'l2_leaf_reg': 6.133576887613275, 'max_bin': 111, 'random_strength': 2.0929199809151737, 'bagging_temperature': 0.3835603364559823}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:22:35,227] Trial 94 finished with value: 1.1802401564017666 and parameters: {'depth': 7, 'learning_rate': 0.022290658188293025, 'l2_leaf_reg': 6.7206003555761225, 'max_bin': 102, 'random_strength': 1.82124578304663, 'bagging_temperature': 0.4166817516918363}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:24:46,676] Trial 95 finished with value: 1.178036055234208 and parameters: {'depth': 7, 'learning_rate': 0.02230467792891769, 'l2_leaf_reg': 7.041514244465679, 'max_bin': 100, 'random_strength': 1.6930138663101464, 'bagging_temperature': 0.32280838282783925}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:27:10,367] Trial 96 finished with value: 1.1794788840971 and parameters: {'depth': 7, 'learning_rate': 0.019767049223335574, 'l2_leaf_reg': 6.740412787586074, 'max_bin': 104, 'random_strength': 3.0242788688069315, 'bagging_temperature': 0.2634612878393874}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:29:41,568] Trial 97 finished with value: 1.1757044950524194 and parameters: {'depth': 7, 'learning_rate': 0.019916429389958676, 'l2_leaf_reg': 6.63953768409901, 'max_bin': 105, 'random_strength': 3.1083770191186795, 'bagging_temperature': 0.26849729434634556}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:31:55,124] Trial 98 finished with value: 1.178802286680016 and parameters: {'depth': 7, 'learning_rate': 0.02449540388555187, 'l2_leaf_reg': 7.6416415096097, 'max_bin': 102, 'random_strength': 1.947247782449828, 'bagging_temperature': 0.19485967137365853}. Best is trial 19 with value: 1.1810765878429639.\n[I 2025-10-22 04:34:07,600] Trial 99 finished with value: 1.1795319474938353 and parameters: {'depth': 7, 'learning_rate': 0.023238786537760875, 'l2_leaf_reg': 8.377985421246553, 'max_bin': 104, 'random_strength': 2.587030773739547, 'bagging_temperature': 0.3432799847547775}. Best is trial 19 with value: 1.1810765878429639.\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizasyon tamamlandÄ±. En iyi parametreler bulundu: {'depth': 7, 'learning_rate': 0.02499651068043169, 'l2_leaf_reg': 9.80533396785614, 'max_bin': 57, 'random_strength': 8.16859210701793, 'bagging_temperature': 0.618517454284633}\n\n7-Fold StratifiedKFold ile eÄŸitim baÅŸlÄ±yor...\n===== Fold 1 =====\n0:\tlearn: 0.6749226\ttest: 0.6749128\tbest: 0.6749128 (0)\ttotal: 48.2ms\tremaining: 4m 49s\n500:\tlearn: 0.3612542\ttest: 0.3690819\tbest: 0.3690819 (500)\ttotal: 26.7s\tremaining: 4m 52s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3676766053\nbestIteration = 899\n\nShrink model to first 900 iterations.\n===== Fold 2 =====\n0:\tlearn: 0.6749748\ttest: 0.6750350\tbest: 0.6750350 (0)\ttotal: 60.3ms\tremaining: 6m 1s\n500:\tlearn: 0.3617863\ttest: 0.3670786\tbest: 0.3670786 (500)\ttotal: 26.8s\tremaining: 4m 54s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3659330196\nbestIteration = 870\n\nShrink model to first 871 iterations.\n===== Fold 3 =====\n0:\tlearn: 0.6750130\ttest: 0.6749722\tbest: 0.6749722 (0)\ttotal: 54.3ms\tremaining: 5m 25s\n500:\tlearn: 0.3616779\ttest: 0.3667506\tbest: 0.3667506 (500)\ttotal: 26.8s\tremaining: 4m 53s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3661498641\nbestIteration = 709\n\nShrink model to first 710 iterations.\n===== Fold 4 =====\n0:\tlearn: 0.6749532\ttest: 0.6750481\tbest: 0.6750481 (0)\ttotal: 52ms\tremaining: 5m 11s\n500:\tlearn: 0.3611894\ttest: 0.3707363\tbest: 0.3707363 (500)\ttotal: 26.4s\tremaining: 4m 49s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3699297358\nbestIteration = 852\n\nShrink model to first 853 iterations.\n===== Fold 5 =====\n0:\tlearn: 0.6749649\ttest: 0.6749123\tbest: 0.6749123 (0)\ttotal: 50.7ms\tremaining: 5m 4s\n500:\tlearn: 0.3614236\ttest: 0.3690083\tbest: 0.3690083 (500)\ttotal: 26.7s\tremaining: 4m 52s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3676081811\nbestIteration = 904\n\nShrink model to first 905 iterations.\n===== Fold 6 =====\n0:\tlearn: 0.6748348\ttest: 0.6749384\tbest: 0.6749384 (0)\ttotal: 50.8ms\tremaining: 5m 4s\n500:\tlearn: 0.3613483\ttest: 0.3686127\tbest: 0.3686127 (500)\ttotal: 26.4s\tremaining: 4m 49s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3674051743\nbestIteration = 797\n\nShrink model to first 798 iterations.\n===== Fold 7 =====\n0:\tlearn: 0.6749225\ttest: 0.6750941\tbest: 0.6750941 (0)\ttotal: 49.5ms\tremaining: 4m 57s\n500:\tlearn: 0.3610070\ttest: 0.3714158\tbest: 0.3714158 (500)\ttotal: 26.6s\tremaining: 4m 52s\nStopped by overfitting detector  (40 iterations wait)\n\nbestTest = 0.3703445635\nbestIteration = 893\n\nShrink model to first 894 iterations.\n\n==============================================\nFinal OOF Skoru (Kalibrasyon Ã–ncesi): 1.18930\n  -> OlasÄ±lÄ±k kalibrasyonu uygulanÄ±yor...\nFinal OOF Skoru (Kalibrasyon SonrasÄ±): 1.19174\n==============================================\n\nSHAP DeÄŸerleri HesaplanÄ±yor ve Grafik Ã‡iziliyor...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nÄ°ÅŸlem tamamlandÄ± ve 'submission_catboost_calibrated.csv' dosyasÄ± oluÅŸturuldu.\n\nNihai iÅŸlem tamamlandÄ±. GÃ¶nderim dosyasÄ±nÄ±n ilk 5 satÄ±rÄ±:\n   cust_id     churn\n0        1  0.132502\n1        2  0.116461\n2        9  0.237685\n3       15  0.225490\n4       19  0.045316\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}